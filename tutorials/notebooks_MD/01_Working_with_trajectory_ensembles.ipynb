{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Working with trajectory ensembles\n",
    "\n",
    "**Welcome**\n",
    "\n",
    "Welcome to the MD section of the EncoderMap tutorial. All EncoderMap tutorials are provided as jupyter notebooks, that you can run locally, on binderhub, or even on google colab.\n",
    "\n",
    "\n",
    "Run this notebook on Google Colab:\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AG-Peter/encodermap/blob/main/tutorials/notebooks_MD/01_Working_with_trajectory_ensembles.ipynb)\n",
    "\n",
    "Find the documentation of EncoderMap:\n",
    "\n",
    "https://ag-peter.github.io/encodermap\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "In this tutorial you will learn:\n",
    "- [What CVs are.](#primer)\n",
    "- [How EncoderMaps' new `SingleTraj` class loads MD data.](#singletraj)\n",
    "- [How a `SingleTraj` can be associated with CVs.](#load_CVs)\n",
    "\n",
    "### For Google colab only:\n",
    "\n",
    "If you're on Google colab, please uncomment these lines and install EncoderMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/install_encodermap_google_colab.sh\n",
    "# !sudo bash install_encodermap_google_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='primer'></a>\n",
    "\n",
    "## Primer\n",
    "\n",
    "### Collective Variables\n",
    "\n",
    "Collective Variables (CVs) are often used to simplify and filter the xyz-Data of MD simulations. They are often employed to make sense of a complex protein (or more general molecular) system by breaking it down into just a few well-defined descriptors. They are similar to reaction coordinates, which are 1-dimensional variables along a reaction pathway but can be higher dimensional. When we think about a receptor-ligand system, the distance between the two species is often used as a reaction coordinate. A set of this distance CV and the relative rotation between receptor and ligand can add much more information and help understand the system. It becomes apparent that clever selection of CVs is an important task that many scientists in different fields face day to day.\n",
    "\n",
    "<!-- <img src=\"CV_overview.png\" width=\"900\" align=\"center\"> -->\n",
    "\n",
    "With the tools presented in this notebook you will be able to work in a fluent and natural way with MD trajectories and their associated CV data. In the scope of this work we define CVs as:\n",
    "\n",
    "**a collection of data that is in one of its dimensions aligned with the frames/timesteps of the underlying simulation data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Example CVs\n",
    "\n",
    "Here's a list of widely used CVs:\n",
    "\n",
    "- Distances: This category of CVs can contain a 1-diemsnional scalar value describing the distance between two species in a receptor-ligand system. A 1-dimensional CV of the end-to-end distance of a protein can describe the proteins folding state in an approximate and generalizing manner. Distance CVs can also be higher-dimensional. The pairwise distances between $\\mathrm{C_\\alpha}$ atoms of a protein with $n$ residues can be captured as a $n \\times n$ matrix. A so-called hollow matrix, where all diagonal-elements are zero which is also symmetric. Most often a vector of length $\\binom{n}{2}$ is used to describe the pairwise distances in a protein. The distance between a protein and a membrane/interface would also fall into this category.\n",
    " \n",
    "- Angles: Angular CVs lie in a periodic space of $(-\\pi, \\pi]$ or $(0, 2\\pi]$, or $(0, 360]$. The well-known Ramachandran plot uses a protein's $\\phi$ and $\\psi$ angles to define regions of $psi$-$phi$ combinations which correlate to different secondary structure motifs. Besides the backbone angles other angles can become important in understanding a protein's conformations. Lysine is often modified via acetylation, phosphorylation, methylation, ubiquitylation and it's sidechain angles ($\\chi_1$ to $\\chi_5$) can be important descriptors in such a system. Pseudo-Dihedral angles lie also in this category. \n",
    "\n",
    "- Integer/binary values. If a protein has well-defined states (folded and unfolder) a binary value describing these states could also be a useful CV.\n",
    "\n",
    "- Values from other calculations and hyperparameters. An example for this category could be the temperature at which the simulation was carried out, when simulations were conducted at multiple temperatures. If phase space sub states were obtained by either using Markov-Chain models, or by using some sort of clustering algorithm (GROMOS), the membership to such cluster could also present CVs.\n",
    "\n",
    "- Positional values: Maybe even the full position of an atom or a group of atoms could be an important descriptor for a system.\n",
    "\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw data\n",
    "\n",
    "We can view the raw xyz-data of trajectories as a high-dimensional array with a shape of (n_frames, n_atoms, 3). The last axis correxponds to the cartesian coordinates. Indexing this axis will give us the *x*, *y*, and *z* coordinates, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: delete\n",
    "from __future__ import annotations\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import encodermap as em\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.load_project('linear_dimers', traj=0)\n",
    "\n",
    "print(f\"First frame, first atom, x-coordinate:\\n{traj.xyz[0, 0, 0]=}\")\n",
    "print(f\"First 2 frames, first atom, y-coordinates:\\n{traj.xyz[:2, 0, 1]=}\")\n",
    "print(f\"All frames, all atoms. Only z-coordinates:\\n{traj.xyz[..., -1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3-dimensions of this data can be used for plotting. However, we don't gain much from these plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot.raw_data_plot(\n",
    "    traj,\n",
    "    frame_slice=slice(0, 5001, 1000),\n",
    "    atom_slice=slice(0, 1500, 150),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more context to the raw xyz-data (like size, color, bonds) we can better understand the data. However, we can't really understand how the protein moves from one folding state to another. Hit the \"Play\" button and have a look at the first 200 frames of the simulation. Can you spot the LEU56-SER57-ASP58-TYR59 residues transition from a turn into an $\\alpha$-helix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot.ball_and_stick_plot(\n",
    "    traj,\n",
    "    subsample=slice(0, 200, 20),\n",
    "    animation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collective variables\n",
    "\n",
    "That's when collective variables can come in handy. They break down and combine different xyz data to help us understand the grand picture of protein folding.\n",
    "\n",
    "##### Angles\n",
    "\n",
    "A Ramachandran plot is a very general description of secondary structure motifs. The test protein does indeed contain $alpha$-helices and $beta$-sheets. We can't really understand the conformation of the protein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot.ramachandran_plot(traj, subsample=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DSSP plot doesn't condense the $phi$ and $psi$ angles into a single plot. Here we can assign secondary structure motifs to certain residues at certain times of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot.dssp_plot(\n",
    "    traj,\n",
    "    simplified=False,\n",
    "    subsample=slice(0, 500),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distances\n",
    "\n",
    "Distances can also be used as useful collective variables. The end-to-end distance can give helpful insights into a proteins general conformation (collapsed vs. extended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.plot.end2end_plot(traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing MD data\n",
    "\n",
    "To play with MD data we must first obtain them. Instead of running long MD simulations you can just download the datasets from the University of Konstanz' data repository KonDATA. EncoderMap has a convenience function `get_from_kondata()`, that allows you to fetch those files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encodermap as em\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "output_dir = em.get_from_kondata(\n",
    "    \"linear_dimers\",\n",
    "    mk_parentdir=True,\n",
    "    silence_overwrite_message=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='singletraj'></a>\n",
    "\n",
    "## Classes for working with MD data\n",
    "\n",
    "After we have obtained some files let us work with Encodermap's `SingleTraj` and `TrajEnsemble` classes. We need some more imports to also plot some data and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for numerical data\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Packages for MD data\n",
    "import mdtraj as md\n",
    "import MDAnalysis as mda\n",
    "\n",
    "# Packages for plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Packages for file operations\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "# nice printing\n",
    "from rich.pretty import pprint\n",
    "\n",
    "# With nglview you can view structural data in the notebook\n",
    "# If not installed you should check it out.\n",
    "try:\n",
    "    import nglview as nv\n",
    "except ImportError:\n",
    "    print(\"Check out nglview: https://github.com/nglviewer/nglview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### The new `SingleTraj` class\n",
    "\n",
    "The `SingleTraj` class is meant as a container to hold a trajectory's xyz coordinates, its topology, and its CVs. This class builds the backbone of the `TrajEnsemble` class which will be looked at later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Initialization\n",
    "\n",
    "In the background of the `SingleTraj` class the MDTraj package (https://github.com/mdtraj/mdtraj) works its magic, however this class offers more benefits:\n",
    "\n",
    "- The `SingleTraj` class keeps track of CVs while indexing and slicing.\n",
    "- The trajectories' xyz data is only loaded when it is actually needed. Most manipuilation can thus be done before creating huge objects in memory.\n",
    "\n",
    "The `SingleTraj` class can be initialized in many ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From a trajectory file (.xtc, .dcd, .lammpstrj) and a topology file (.gro, .pdb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(output_dir)\n",
    "traj_from_xtc_file = em.SingleTraj(output_dir / \"01.xtc\", top=output_dir / \"01.pdb\")\n",
    "print(traj_from_xtc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From an url of the pdb database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_from_url = em.SingleTraj('https://files.rcsb.org/view/1YUF.pdb')\n",
    "print(traj_from_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Or by just by providing a pdb code to the `from_pdb_id()` constructor of the `SingleTraj` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_from_pdb_id = em.SingleTraj.from_pdb_id('1YUG')\n",
    "print(traj_from_pdb_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also directly load the trajectory from an EncoderMap project. In this case, the trajectory already has CVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the load_project() method\n",
    "traj = em.load_project('linear_dimers', traj=0)\n",
    "print(traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**`SingleTraj`s keep track of the files they have been instantiated from.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"basename  = {traj_from_xtc_file.basename:<70}{traj_from_url.basename:<70}\\n\"\n",
    "    f\"traj_file = {traj_from_xtc_file.traj_file:<70}{traj_from_url.traj_file:<70}\\n\"\n",
    "    f\"top_file  = {traj_from_xtc_file.top_file:<70}{traj_from_url.top_file:<70}\\n\"\n",
    "    f\"extension = {traj_from_xtc_file.extension:<70}{traj_from_url.extension:<70}\\n\"\n",
    "    f\"n_frames  = {traj_from_xtc_file.n_frames:<70}{traj_from_url.n_frames:<70}\\n\"\n",
    "    f\"n_atoms   = {traj_from_xtc_file.n_atoms:<70}{traj_from_url.n_atoms:<70}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### On demand loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Difference between `traj`, `trajectory` and `top`, `topology`**\n",
    "\n",
    "`traj` and `top` always give `mdtraj.Trajectory` and `mdtraj.Topology`, respectively. They are loaded *on demand* and return the corresponding `mdtraj` object..\n",
    "\n",
    "`trajectory` and `topology` can be `False` and represent the current *backend* of the TrajEnsemble object.\n",
    "\n",
    "When instantiated, `SingleTraj` do not load the data from disk. Only when requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj_from_xtc_file.topology)\n",
    "print(traj_from_xtc_file.top)\n",
    "print(traj_from_xtc_file.topology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj_from_xtc_file.trajectory)\n",
    "print(traj_from_xtc_file.traj)\n",
    "print(traj_from_xtc_file.trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Loading can be forced**\n",
    "\n",
    "Using the `load()` method, the trajectory will be loaded. From that point forwards, the xyz data is kept in RAM and can be accessed. The `unload()` function does the reverse and frees up the RAM, but the xyz data can be loaded again. If your RAM is large enough you would not need the `unload()` function, but it is there nonetheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_from_xtc_file.load_traj()\n",
    "print(traj_from_xtc_file.topology)\n",
    "traj_from_xtc_file.unload()\n",
    "print(traj_from_xtc_file.topology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside a context manager, the `SingleTraj` is always loaded and unloaded afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with traj_from_xtc_file as t:\n",
    "    print(t.topology)\n",
    "print(traj_from_xtc_file.topology)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Look at trajs with nglview\n",
    "\n",
    "If nglview is set up, you can take a look at the trajectory with this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = traj_from_xtc_file.show_traj()\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Duplication of mdtraj\n",
    "\n",
    "Some methods and attributes are duplicated from `mdtraj`. This allows us to call some `mdtraj` functions on the `SingleTraj` object directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = traj_from_xtc_file.select('name CA')\n",
    "print(selection[:5])\n",
    "dssp = md.compute_dssp(traj_from_xtc_file)\n",
    "print(dssp[0, :5].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.compute_center_of_mass(traj_from_xtc_file)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Indexing\n",
    "\n",
    "By indexing a `SingleTraj`, you get another instance of `SingleTraj` containing only one frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = traj_from_xtc_file[0]\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The indexing of `SingleTraj`s is postponed, meaning, that for certain indexing types (integers, sequences of integers, slices without the step argument) the trajectory data is not loaded from disk. Only, when loaded, are the indexes applied one after the other.\n",
    "\n",
    "This cell is fast. No file operations are carried out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_from_xtc_file.unload()\n",
    "frame = traj_from_xtc_file[:10][[0, 1]]\n",
    "print(frame)\n",
    "print(frame.trajectory)\n",
    "print(frame.n_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is a bit slower. Here, the trajectory is loaded from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.load_traj()\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If the index is larger than the number of frames, the `SingleTraj` class will throw an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_from_xtc_file.unload()\n",
    "frame = traj_from_xtc_file[10_000]\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing with `.fsel` (frame select)\n",
    "\n",
    "`SingleTraj`s keep the number of their frames organized. If a `SingleTraj` is loaded, the frames can be represented by a list of integers: `[0, 1, 2, ..., n_frames]`. Indexing these frames with a `[::2]` slice will give the frames `[0, 2, 4, ..., n]`. If you then index the `SingleTraj` with `[2]`, you will receive frame 4 from the original trajectory. Indexing frames by their original number is done with the `fsel[]` selector of the `SingleTraj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj[::2][2].time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj[::2].fsel[4].time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fsel[]` selector allows for more selections. All based on the original frame number. Think of it like pandas `.iloc` and `.loc` selectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.fsel[[4, 8, 12]].time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, that some frames are not accessible, when we do some weird slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj[10].fsel[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Advanced slicing\n",
    "\n",
    "You can also give a numpy array, a list or even a slice into the indexing.\n",
    "\n",
    "Indexing with without a stop (`[::5]`) will put the trajectory into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_from_xtc_file.unload()\n",
    "subsample = traj_from_xtc_file[::2]\n",
    "print(traj_from_xtc_file.n_frames)\n",
    "print(subsample)\n",
    "print(subsample.n_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_from_xtc_file.unload()\n",
    "subsample = traj_from_xtc_file[[0, 1, 5, 6]]\n",
    "print(subsample)\n",
    "print(subsample.n_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Note:**\n",
    "Andvanced slicing can result in trajectories with 0 frames in them, or possibly reverse the time axis. Use this feature only if you are sure about what you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_from_xtc_file.unload()\n",
    "subsample = traj_from_xtc_file[5:46:3]\n",
    "print(subsample)\n",
    "print(subsample.n_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Advanced slicing with HDF5\n",
    "\n",
    "The HDF5 file format (ending wiht the .h5 extension) allows us to directly extract frames and accelerate loading.\n",
    "We can save a .h5 formatted file from an `SingleTraj` class by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    d = Path(d)\n",
    "    traj_from_xtc_file.save(d / 'my_traj.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Loading of .h5 files is similar to all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    d = Path(d)\n",
    "    traj_from_xtc_file.save(d / 'my_traj.h5', overwrite=True)\n",
    "    traj_h5 = em.SingleTraj(d / 'my_traj.h5')\n",
    "\n",
    "    print(traj_h5[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration\n",
    "\n",
    "The `SingleTraj` class can be used as an iterator in two ways:\n",
    "\n",
    "- Iterate over the frames with `for frame in traj`.\n",
    "- Iterate over frame_number and frame with `for frame_no, frame in traj.iterframes()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in traj[::2][:5]:\n",
    "    print(frame.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_num, frame in traj[::2][:5].iterframes():\n",
    "    print(frame_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `TrajEnsemble` class contains multiple `SingleTraj`s\n",
    "\n",
    "> The trajectory ensemble is everything youâ€™ve always wanted, and more.  Really, it is.  Trajectory ensembles unlock fundamental ideas in statistical mechanics, including connections between equilibrium and non-equilibrium phenomena.\n",
    "- Daniel M. Zuckerman (https://statisticalbiophysicsblog.org/?p=92#more-92)\n",
    "\n",
    "EncoderMap tries to implement the idea of a trajectory ensemble with the `TrajectoryEnsemble` class. A container for multiple `SingleTraj`s.\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "A trajectory ensemble can be created by providing it multiple trajectory files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(em.get_from_kondata(\"pASP_pGLU\", mk_parentdir=True, silence_overwrite_message=True))\n",
    "\n",
    "trajs_from_files = em.load(\n",
    "    [\n",
    "        output_dir / \"asp7.xtc\",\n",
    "        output_dir / \"glu7.xtc\",\n",
    "    ],\n",
    "    [\n",
    "        output_dir / \"asp7.pdb\",\n",
    "        output_dir / \"glu7.pdb\",\n",
    "    ],\n",
    "    common_str=[\"asp7\", \"glu7\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_from_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `common_str` argument provides a means to group similar trajectories. It searches for matching substrings in the filename of the provided trajectories and topologies. In the `trajs_from_files`, there are only one `TrajEnsemble` with a single trajectory per `common_str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(trajs_from_files.trajs_by_common_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TrajEnsemble`s are not limited to a single topology\n",
    "\n",
    "Something that EncoderMap does different than packages like `MDTraj` or `MDAnalysis` is that trajectories can be grouped together even when their topologies are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(trajs_from_files.trajs_by_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `trajs_from_files` instance has trajectories with 2 different topologies in it. This feature is meant to represent the expression of mutations in biological systems. Older versions\n",
    "\n",
    "https://evolution.berkeley.edu/dna-and-mutations/types-of-mutations/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing `TrajEnsemble`s\n",
    "\n",
    "Indexing `TrajEnsemble`s can yield different output types. Indexing with a sinlge `int` will yield the corresponding trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs_from_files[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lists, numpy_arrays and fance slices (`[1:10:2]`) can also be used for indexing. Indexing trajectories by their `traj_num` is done with the `tsel[]` selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = trajs_from_files.copy()\n",
    "trajs[0].traj_num = 10\n",
    "trajs[1].traj_num = 20\n",
    "trajs.tsel[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs.tsel[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TrajEnsemble`s can be created by adding two `SinlgeTraj`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs[0] + trajs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TrajEnsemble`s can also be loaded from EncoderMap's projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = em.load_project(\"pASP_pGLU\")\n",
    "trajs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id='load_CVs'></a>\n",
    "\n",
    "## Loading CVs\n",
    "\n",
    "After learning about the basics of the `SingleTraj` and `TrajEnsemble` class we will come back to collective variables. There are many ways of adding CVs to you trajectories. The easiest would be to provide an already existing numpy array. However, you will be asked to also provide the attribute name (`attr_name`) of the array. With this you could load multiple CV datasets, that differ in ther attribute names. Here's an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### From numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the traj to make the following code more readable\n",
    "traj = traj_from_xtc_file\n",
    "\n",
    "# random phi/psi angles in a [0, 2pi] interval\n",
    "random_raman_angles = np.random.random((traj.n_frames, 2 * traj.n_residues)) * 2 * np.pi\n",
    "\n",
    "# define labels:\n",
    "phi_angles = [f'phi {i}' for i in range(traj.n_residues)]\n",
    "psi_angles = [f'psi {i}' for i in range(traj.n_residues)]\n",
    "raman_labels = [None]*(len(phi_angles)+len(psi_angles))\n",
    "raman_labels[::2] = phi_angles\n",
    "raman_labels[1::2] = psi_angles\n",
    "\n",
    "# load the CV\n",
    "traj.load_CV(random_raman_angles, 'raman', labels=raman_labels)\n",
    "\n",
    "# define some integer values (can be cluster memberships)\n",
    "random_integers_per_frame = np.random.randint(0, 3, size=traj.n_frames)\n",
    "traj.load_CV(random_integers_per_frame, 'cluster_membership')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "These values can be accessed via directly calling their attribute names (so make sure to use valid identifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj.cluster_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj.raman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There's also the attribute `CVs` that is a dict of these collective variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.CVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "However, this is not the end. CVs in a `SingleTraj` class are stored as `xarray.Dataset`s. The dataset can be accessed via `_CVs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj._CVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Why xarray?**\n",
    "\n",
    "The underlying `xarray.Dataset` is intended to make sure \"everything is correct\". Every value can be accessed via an unambigous identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj._CVs['raman'].loc[{'frame_no': 20, 'RAMAN': 'psi 50'}].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Slicing with CVs.\n",
    "\n",
    "Slicing keeps your values where they should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(np.array(raman_labels) == 'psi 50')\n",
    "print(traj[20].raman[index])\n",
    "print(traj[[0, 5, 10, 20]].raman[:,index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading from files\n",
    "\n",
    "CVs can be loaded by providing a string to files. First, let us save some files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy\n",
    "np.save('raman_file.npy', traj.raman)\n",
    "\n",
    "# save text\n",
    "np.savetxt('cluster_membership_file.txt', traj.cluster_membership)\n",
    "\n",
    "# save full CV dataset as NetCDF\n",
    "traj._CVs.to_netcdf('full_CV_dataset.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If not providing an `attr_name`, while loading files, the filename will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.load_CV('raman_file.npy')\n",
    "traj.load_CV('cluster_membership_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj.CVs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Multiple CVs can be reconstructed from xarray NetCDF files (most end with .nc). If there are conflicts the new data from disk will overwrite the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "print(traj.CVs.keys())\n",
    "traj.load_CV('full_CV_dataset.nc')\n",
    "print(traj.CVs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading with PyEMMA featurizer\n",
    "\n",
    "We will now use PyEMMA's featurization pipeline (http://emma-project.org/latest/) to load CV data into our trajectory. For this encodermap has its own Version of PyEMMA's featurizer accessible with `em.Featurizer` which can simply be provided to the `SingleTraj` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encodermap as em\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "\n",
    "# instantiate featurizer\n",
    "feat = em.Featurizer(traj)\n",
    "\n",
    "# add features\n",
    "feat.add_backbone_torsions()\n",
    "\n",
    "# load\n",
    "traj.load_CV(feat, attr_name='backbone_torsion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Possible `add_*` features can be found via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for attr in dir(feat):\n",
    "    if attr.startswith('add_'):\n",
    "        help(getattr(feat, attr))\n",
    "        i += 1\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The advantages of this method are:\n",
    "\n",
    "- The same can be done with the `TrajEnsemble` class (more on that later), which is also parallelized.\n",
    "- Most of the features contain comprehensive labels themselves.\n",
    "\n",
    "The labels can be accessed via the `.coordinates` attribute of the `SingleTraj`'s `xarray.Dataset`. They are similar to the `attr_names` but without underscores and all caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj._CVs.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj._CVs.coords['BACKBONETORSIONFEATURE'].values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, it can be seen, that there are some errors on PyEMMA's backbone_torsion feature. The sequence of backbone angles is scrambled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading with Encodermap Features\n",
    "\n",
    "Encodermap features inherit from pyemma, but they are better formatted, regarding the labels. They can be loaded via `traj.load_CV('all')` to load all, or via a single string of list of these strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodermap.misc.misc import FEATURE_NAMES\n",
    "print(FEATURE_NAMES.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "traj.load_CV(['central_angles', 'central_dihedrals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj._CVs.coords['CENTRAL_DIHEDRALS'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj._CVs.coords['CENTRAL_ANGLES'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wrtiting custom features No 1\n",
    "\n",
    "Writing your custom features can be done by subclassing pyemma's features. Required methods and attributes to make your feature work are:\n",
    "\n",
    "- The class-level attributes `__serialize_version` and `__serialize_fields`\n",
    "- The methods `__init__`, `describe`, and `transform`.\n",
    "- The instance attribute `dimension`, which defines the shape of the returned array.\n",
    "\n",
    "If you want to change the name of the feature, as it appears in the `xarray.Dataset` you can set the attribute `name`.\n",
    "\n",
    "In the next cell we will define a Feature that provides a random integer to an atom, based on its hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encodermap as em\n",
    "from encodermap.loading.features import Feature\n",
    "import copy\n",
    "\n",
    "class RandomIntForAtomFeature(Feature):\n",
    "    # class inherits from encodermap CustomFeature\n",
    "    # set required class-level variables\n",
    "    __serialize_version = 0\n",
    "    __serialize_fields = ('indexes', 'selstr', )\n",
    "    \n",
    "    # write an __init__\n",
    "    def __init__(self, top, selstr='all'):\n",
    "        \"\"\"Init of RandomIntoForAtomFeature.\n",
    "        \n",
    "        Args:\n",
    "            top (mdtraj.Topology): The topology to select atoms from.\n",
    "            \n",
    "        Keyword Args:\n",
    "            selstr (str, optional): The string to provide to top.select().\n",
    "            Defaults to 'all'.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Copy top to save it from hypothetical changes\n",
    "        self.top = copy.deepcopy(top)\n",
    "        \n",
    "        # define indexes (this is one of the serializable fields,\n",
    "        # which could be used by pyemma to save a feature to disk.)\n",
    "        self.indexes = top.select(selstr)\n",
    "        \n",
    "        # set dimension\n",
    "        self.dimension = len(self.indexes)\n",
    "        \n",
    "        # inherit missing methods from base\n",
    "        super().__init__()\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"This method is not allowed to take any arguments.\n",
    "        \n",
    "        This method provides labels.\n",
    "        \n",
    "        Returns:\n",
    "            list: A lsit of str, each str describing one feature.\n",
    "            \n",
    "        \"\"\"\n",
    "        # In this method we will build a list of str\n",
    "        # Each str should describe one of our features\n",
    "        # We assign ints to atoms, so the labels should tell something about the atoms\n",
    "        getlbl = lambda at: f\"atom {at.name:>4}:{at.index:5} {at.residue.name}:{at.residue.resSeq:>4}\"\n",
    "        labels = []\n",
    "        for i in self.indexes:\n",
    "            i = self.top.atom(i)\n",
    "            labels.append(f\"Random int for {getlbl(i)}\")\n",
    "        return labels\n",
    "    \n",
    "    def transform(self, traj):\n",
    "        \"\"\"This method provides values.\n",
    "        \n",
    "        Args:\n",
    "            traj (mdtraj.Trajectory): An mdtraj.Trajectory.\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: The values of the features defined in describe.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Make sure that the returned array has correct shape\n",
    "        # In general it is a good idea, that this array has the same length as\n",
    "        # the trajectory has frames\n",
    "        # In general means, like, ..., always\n",
    "        values = traj.xyz[:,:,0].astype(int)\n",
    "        for i in self.indexes:\n",
    "            values[:,i] = int(str(hash(str(self.top.atom(i))))[-5:])\n",
    "        return values\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        # define the name of the feature to appear in `SingleTraj._CVs`\n",
    "        return 'MyAwesomeFeature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "print(traj)\n",
    "featurizer = em.Featurizer(traj)\n",
    "feat = RandomIntForAtomFeature(traj.top)\n",
    "for i in feat.describe()[:200:25]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer.add_custom_feature(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.load_CV(featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj._CVs.coords['MYAWESOMEFEATURE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Writing custom features No 2\n",
    "\n",
    "In this example we will implement a method of calculating a nematic order parameter. This example will be quite different (working with coarse-grained carbon-hydrate chains (so-called telechelics), and not with proteins), but we will work our way through. Here are some references you might consider:\n",
    "\n",
    "```\n",
    "@article{mukherjee2012derivation,\n",
    "  title={Derivation of coarse grained models for multiscale simulation of liquid crystalline phase transitions},\n",
    "  author={Mukherjee, Biswaroop and Delle Site, Luigi and Kremer, Kurt and Peter, Christine},\n",
    "  journal={The Journal of Physical Chemistry B},\n",
    "  volume={116},\n",
    "  number={29},\n",
    "  pages={8474--8484},\n",
    "  year={2012},\n",
    "  publisher={ACS Publications}\n",
    "}\n",
    "\n",
    "@article{flachmuller2021coarse,\n",
    "  title={Coarse grained simulation of the aggregation and structure control of polyethylene nanocrystals},\n",
    "  author={Flachm{\\\"u}ller, Alexander and Mecking, Stefan and Peter, Christine},\n",
    "  journal={Journal of Physics: Condensed Matter},\n",
    "  volume={33},\n",
    "  number={26},\n",
    "  pages={264001},\n",
    "  year={2021},\n",
    "  publisher={IOP Publishing}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Saving trajectory and CVs into one file\n",
    "\n",
    "A trajectory can (with its CVs) saved as one comprehensive file with the `save()` method. What's more: Loading such a file again makes it possible to access any frames and their corresponding CVs almost instantaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "traj.load_CV('all')\n",
    "traj.save('1am7_all_CVs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_traj = em.SingleTraj('1am7_all_CVs.h5')\n",
    "frames = new_traj[[0, 5, 20, 35]]\n",
    "frames.CentralCartesians.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = new_traj[::5]\n",
    "print(frames.CentralBondDistances.shape)\n",
    "print(frames._CVs.coords['CENTRALBONDDISTANCES'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "However, CVs are deleted, when the number of atoms is altered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = frames.atom_slice(frames.select('name CA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(np.array(raman_labels) == 'psi 50')\n",
    "print(traj[20].raman[index])\n",
    "print(traj[[0, 5, 10, 20]].raman[:,index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading from files\n",
    "\n",
    "CVs can be loaded by providing a string to files. First, let us save some files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy\n",
    "np.save('raman_file.npy', traj.raman)\n",
    "\n",
    "# save text\n",
    "np.savetxt('cluster_membership_file.txt', traj.cluster_membership)\n",
    "\n",
    "# save full CV dataset as NetCDF\n",
    "traj._CVs.to_netcdf('full_CV_dataset.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If not providing an `attr_name`, while loading files, the filename will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.load_CV('raman_file.npy')\n",
    "traj.load_CV('cluster_membership_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj.CVs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Multiple CVs can be reconstructed from xarray NetCDF files (most end with .nc). If there are conflicts the new data from disk will overwrite the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "print(traj.CVs.keys())\n",
    "traj.load_CV('full_CV_dataset.nc')\n",
    "print(traj.CVs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading with PyEMMA featurizer\n",
    "\n",
    "We will now use PyEMMA's featurization pipeline (http://emma-project.org/latest/) to load CV data into our trajectory. For this encodermap has its own Version of PyEMMA's featurizer accessible with `em.Featurizer` which can simply be provided to the `SingleTraj` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encodermap as em\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "\n",
    "# instantiate featurizer\n",
    "feat = em.Featurizer(traj)\n",
    "\n",
    "# add features\n",
    "feat.add_backbone_torsions()\n",
    "\n",
    "# load\n",
    "traj.load_CV(feat, attr_name='backbone_torsion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Possible `add_*` features can be found via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for attr in dir(feat):\n",
    "    if attr.startswith('add_'):\n",
    "        help(getattr(feat, attr))\n",
    "        i += 1\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The advantages of this method are:\n",
    "\n",
    "- The same can be done with the `TrajEnsemble` class (more on that later), which is also parallelized.\n",
    "- Most of the features contain comprehensive labels themselves.\n",
    "\n",
    "The labels can be accessed via the `.coordinates` attribute of the `SingleTraj`'s `xarray.Dataset`. They are similar to the `attr_names` but without underscores and all caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj._CVs.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj._CVs.coords['BACKBONETORSIONFEATURE'].values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, it can be seen, that there are some errors on PyEMMA's backbone_torsion feature. The sequence of backbone angles is scrambled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading with Encodermap Features\n",
    "\n",
    "Encodermap features inherit from pyemma, but they are better formatted, regarding the labels. They can be loaded via `traj.load_CV('all')` to load all, or via a single string of list of these strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encodermap.misc.misc import FEATURE_NAMES\n",
    "print(FEATURE_NAMES.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "traj.load_CV(['central_angles', 'central_dihedrals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj._CVs.coords['CENTRAL_DIHEDRALS'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj._CVs.coords['CENTRAL_ANGLES'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wrtiting custom features No 1\n",
    "\n",
    "Writing your custom features can be done by subclassing pyemma's features. Required methods and attributes to make your feature work are:\n",
    "\n",
    "- The class-level attributes `__serialize_version` and `__serialize_fields`\n",
    "- The methods `__init__`, `describe`, and `transform`.\n",
    "- The instance attribute `dimension`, which defines the shape of the returned array.\n",
    "\n",
    "If you want to change the name of the feature, as it appears in the `xarray.Dataset` you can set the attribute `name`.\n",
    "\n",
    "In the next cell we will define a Feature that provides a random integer to an atom, based on its hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encodermap as em\n",
    "from encodermap.loading.features import Feature\n",
    "import copy\n",
    "\n",
    "class RandomIntForAtomFeature(Feature):\n",
    "    # class inherits from encodermap CustomFeature\n",
    "    # set required class-level variables\n",
    "    __serialize_version = 0\n",
    "    __serialize_fields = ('indexes', 'selstr', )\n",
    "    \n",
    "    # write an __init__\n",
    "    def __init__(self, top, selstr='all'):\n",
    "        \"\"\"Init of RandomIntoForAtomFeature.\n",
    "        \n",
    "        Args:\n",
    "            top (mdtraj.Topology): The topology to select atoms from.\n",
    "            \n",
    "        Keyword Args:\n",
    "            selstr (str, optional): The string to provide to top.select().\n",
    "            Defaults to 'all'.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Copy top to save it from hypothetical changes\n",
    "        self.top = copy.deepcopy(top)\n",
    "        \n",
    "        # define indexes (this is one of the serializable fields,\n",
    "        # which could be used by pyemma to save a feature to disk.)\n",
    "        self.indexes = top.select(selstr)\n",
    "        \n",
    "        # set dimension\n",
    "        self.dimension = len(self.indexes)\n",
    "        \n",
    "        # inherit missing methods from base\n",
    "        super().__init__()\n",
    "        \n",
    "    def describe(self):\n",
    "        \"\"\"This method is not allowed to take any arguments.\n",
    "        \n",
    "        This method provides labels.\n",
    "        \n",
    "        Returns:\n",
    "            list: A lsit of str, each str describing one feature.\n",
    "            \n",
    "        \"\"\"\n",
    "        # In this method we will build a list of str\n",
    "        # Each str should describe one of our features\n",
    "        # We assign ints to atoms, so the labels should tell something about the atoms\n",
    "        getlbl = lambda at: f\"atom {at.name:>4}:{at.index:5} {at.residue.name}:{at.residue.resSeq:>4}\"\n",
    "        labels = []\n",
    "        for i in self.indexes:\n",
    "            i = self.top.atom(i)\n",
    "            labels.append(f\"Random int for {getlbl(i)}\")\n",
    "        return labels\n",
    "    \n",
    "    def transform(self, traj):\n",
    "        \"\"\"This method provides values.\n",
    "        \n",
    "        Args:\n",
    "            traj (mdtraj.Trajectory): An mdtraj.Trajectory.\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: The values of the features defined in describe.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Make sure that the returned array has correct shape\n",
    "        # In general it is a good idea, that this array has the same length as\n",
    "        # the trajectory has frames\n",
    "        # In general means, like, ..., always\n",
    "        values = traj.xyz[:,:,0].astype(int)\n",
    "        for i in self.indexes:\n",
    "            values[:,i] = int(str(hash(str(self.top.atom(i))))[-5:])\n",
    "        return values\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        # define the name of the feature to appear in `SingleTraj._CVs`\n",
    "        return 'MyAwesomeFeature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "print(traj)\n",
    "featurizer = em.Featurizer(traj)\n",
    "feat = RandomIntForAtomFeature(traj.top)\n",
    "for i in feat.describe()[:200:25]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer.add_custom_feature(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.load_CV(featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj._CVs.coords['MYAWESOMEFEATURE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Writing custom features No 2\n",
    "\n",
    "In this example we will implement a method of calculating a nematic order parameter. This example will be quite different (working with coarse-grained carbon-hydrate chains (so-called telechelics), and not with proteins), but we will work our way through. Here are some references you might consider:\n",
    "\n",
    "```\n",
    "@article{mukherjee2012derivation,\n",
    "  title={Derivation of coarse grained models for multiscale simulation of liquid crystalline phase transitions},\n",
    "  author={Mukherjee, Biswaroop and Delle Site, Luigi and Kremer, Kurt and Peter, Christine},\n",
    "  journal={The Journal of Physical Chemistry B},\n",
    "  volume={116},\n",
    "  number={29},\n",
    "  pages={8474--8484},\n",
    "  year={2012},\n",
    "  publisher={ACS Publications}\n",
    "}\n",
    "\n",
    "@article{flachmuller2021coarse,\n",
    "  title={Coarse grained simulation of the aggregation and structure control of polyethylene nanocrystals},\n",
    "  author={Flachm{\\\"u}ller, Alexander and Mecking, Stefan and Peter, Christine},\n",
    "  journal={Journal of Physics: Condensed Matter},\n",
    "  volume={33},\n",
    "  number={26},\n",
    "  pages={264001},\n",
    "  year={2021},\n",
    "  publisher={IOP Publishing}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Saving trajectory and CVs into one file\n",
    "\n",
    "A trajectory can (with its CVs) saved as one comprehensive file with the `save()` method. What's more: Loading such a file again makes it possible to access any frames and their corresponding CVs almost instantaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = em.SingleTraj('1am7_corrected.xtc', '1am7_protein.pdb')\n",
    "traj.load_CV('all')\n",
    "traj.save('1am7_all_CVs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_traj = em.SingleTraj('1am7_all_CVs.h5')\n",
    "frames = new_traj[[0, 5, 20, 35]]\n",
    "frames.CentralCartesians.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = new_traj[::5]\n",
    "print(frames.CentralBondDistances.shape)\n",
    "print(frames._CVs.coords['CENTRALBONDDISTANCES'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "However, CVs are deleted, when the number of atoms is altered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = frames.atom_slice(frames.select('name CA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
