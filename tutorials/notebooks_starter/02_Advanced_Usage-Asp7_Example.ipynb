{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Usage: Asp 7\n",
    "\n",
    "Run this notebook on Google Colab:\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AG-Peter/encodermap/blob/main/tutorials/notebooks_starter/02_Advanced_Usage-Asp7_Example.ipynb)\n",
    "\n",
    "Find the documentation of EncoderMap:\n",
    "\n",
    "https://ag-peter.github.io/encodermap\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "In this tutorial you will learn:\n",
    "- [What's different when data lies in a periodic space.](#periodic-variables)\n",
    "- [How to visualize and observe training progression using `Tensorboard`.](#visualize-learning-with-tensorboard)\n",
    "- [How to use EncoderMap's InteractivePlotting session.](#generate-molecular-conformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Google colab only:**\n",
    "\n",
    "If you're on Google colab, please uncomment these lines and install EncoderMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://gist.githubusercontent.com/kevinsawade/deda578a3c6f26640ae905a3557e4ed1/raw/b7403a37710cb881839186da96d4d117e50abf36/install_encodermap_google_colab.sh\n",
    "# !sudo bash install_encodermap_google_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're on Google colab, you also want to download the data we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/notebooks_starter/asp7.csv\n",
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/notebooks_starter/asp7.pdb\n",
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/notebooks_starter/asp7.xtc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Primer\n",
    "\n",
    "### Imports and load data\n",
    "\n",
    "In this tutorial we will use example data from a molecular dynamics simulation and learn more about advanced usage of EncoderMap. Encoder map can create low-dimensional maps of the vast conformational spaces of molecules. This allows easy identification of the most common molecular conformations and helps to understand the relations between these conformations. In this example, we will use data from a simulation of a simple peptide: hepta-aspartic-acid.\n",
    "\n",
    "First we need to import some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encodermap as em\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from math import pi\n",
    "try:\n",
    "    from google.colab import data_table, output\n",
    "    data_table.enable_dataframe_formatter()\n",
    "    output.enable_custom_widget_manager()\n",
    "    renderer = \"colab\"\n",
    "except ModuleNotFoundError:\n",
    "    renderer = \"plotly_mimetype+notebook\"\n",
    "pio.renderers.default = renderer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the input data. Different kinds of variables can be used to describe molecular conformations: e.g. Cartesian coordinates, distances, angles, dihedrals... In principle EncoderMap can deal with any of these inputs, however, some are better suited than others. The molecular conformation does not change when the molecule is translated or rotated. The chosen input variables should reflect that and be translationally and rotationally invariant. \n",
    "\n",
    "In this example we use the backbone dihedral angles phi and psi as input as they are translationally and rotationally invariant and describe the backbone of a protein/peptide very well.\n",
    "\n",
    "The \"asp7.csv\" file contains one column for each dihedral and one row for each frame of the trajectory. Additionally, the last column contains a cluster_id from a gromos clustering which we can later use for comparison. We can load this data using `np.loadtxt()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"asp7.csv\"\n",
    "data = np.loadtxt(csv_path, skiprows=1, delimiter=\",\")\n",
    "dihedrals = data[:, :-1]\n",
    "cluster_ids = data[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the molecular dynamics simulation right here in this jupyter notebook using the `nglview` package. This cell loads the `asp7.xtc` trajectory and `asp7.pdb` topology file and displays them as a ball and stick representation.\n",
    "\n",
    "If you don't have access to these files, you can replace the line\n",
    "\n",
    "```python\n",
    "traj = md.load('asp7.xtc', top='asp7.pdb')\n",
    "```\n",
    "\n",
    "with\n",
    "\n",
    "```python\n",
    "traj = md.load_pdb('https://files.rcsb.org/view/1YUF.pdb')\n",
    "```\n",
    "\n",
    "to load a small molecular conformation ensemble from the protein database.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "Sometimes the view can be not centered. Use the 'center' button in the gui to center the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "traj = em.load('asp7.pdb')\n",
    "em.plot.plot_ball_and_stick(traj, highlight=\"dihedrals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nglview as nv\n",
    "import mdtraj as md\n",
    "traj = md.load('asp7.xtc', top='asp7.pdb')\n",
    "traj.center_coordinates()\n",
    "view = nv.show_mdtraj(traj, gui=True)\n",
    "view.clear_representations()\n",
    "view.add_representation('ball+stick')\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='periodic-variables'></a>\n",
    "\n",
    "### Periodic variables\n",
    "\n",
    "Periodic variables pose a problem, when we implement a distance metric between two values in a periodic space. When the input space is not-periodic, the euclidean distacen between two points ($p$ and $q$) is given as:\n",
    "\n",
    "\\begin{equation}\n",
    "d(p, q) = \\sqrt{\\left(  p-q \\right)^2}\n",
    "\\end{equation}\n",
    "\n",
    "This equation does not apply when p and q are in a periodic space. Take angle values as an example. Let us assume $p$ and $q$ lie in a periodic space of $(-180^\\circ, 180^\\circ]$ ($-180^\\circ$ is not included, $180^\\circ$ is included) and have the values $p=-100^\\circ$ and $q=150^\\circ$. Plugging that into formula, we get:\n",
    "\n",
    "\\begin{align}\n",
    "d(p, q) &= \\sqrt{\\left(  -100-150 \\right)^2}\\\\\n",
    "&= \\sqrt{\\left( -250 \\right)^2}\\\\\n",
    "&=250\n",
    "\\end{align}\n",
    "\n",
    "However, the distance between these two points is not $250^\\circ$, but $110^\\circ$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "one = go.Scatterpolar(\n",
    "    r=np.full((100, ), 1),\n",
    "    theta=np.linspace(-100, 150, 100),\n",
    "    name=\"250 deg distance\",\n",
    "    hovertemplate=\"250 deg distance\",\n",
    ")\n",
    "two = go.Scatterpolar(\n",
    "    r=np.full((100, ), 1),\n",
    "    theta=np.linspace(0, 110, 100) - 210,\n",
    "    hovertemplate=\"110 deg distance\",\n",
    ")\n",
    "fig = go.Figure(\n",
    "    data=[one, two],\n",
    "    layout={\n",
    "        \"polar\": {\n",
    "            \"radialaxis\": {\n",
    "                \"showticklabels\": False,\n",
    "                \"showgrid\": False,\n",
    "                \"range\": [0.5, 1.5],\n",
    "            },\n",
    "            \"angularaxis\": {\n",
    "                \"tickmode\": \"array\",\n",
    "                \"tickvals\": [0, 45, 90, 135, 180, 225, 270, 315],\n",
    "                \"ticktext\": [0, 45, 90, 135, 180, -135, -90, -45],\n",
    "            },\n",
    "        },\n",
    "        \"showlegend\": False,\n",
    "    },\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance in periodic spaces can be corrected using this formula:\n",
    "\n",
    "\\begin{equation}\n",
    "d_{360}(p, q) = min\\left( d(p, q), 360 - d(p, q) \\right)\n",
    "\\end{equation}\n",
    "\n",
    "Furthermore, during training the the angle values $\\theta$ are converted into value pairs $\\left( sin(\\theta), cos(\\theta) \\right)$ to represent this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter selection\n",
    "\n",
    "Similarly to the previous example, we need to set some parameters. In contrast to the Cube example we now have periodic input data. The dihedral angles are in radians with a 2pi periodicity. We also set some further parameters but don't bother for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = em.Parameters()\n",
    "parameters.main_path = em.misc.run_path(\"runs/asp7\")\n",
    "parameters.n_steps = 100\n",
    "parameters.dist_sig_parameters = (4.5, 12, 6, 1, 2, 6)\n",
    "parameters.periodicity = 2*pi\n",
    "parameters.l2_reg_constant = 10.0\n",
    "parameters.summary_step = 1\n",
    "parameters.tensorboard = True\n",
    "\n",
    "em.plot.distance_histogram_interactive(\n",
    "    dihedrals[::10], \n",
    "    parameters.periodicity, \n",
    "    initial_guess=parameters.dist_sig_parameters,\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can run the dimensionality reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_map = em.EncoderMap(parameters, dihedrals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The new tensorflow 2 version of EncoderMap allows you to also view the output of the latent space during the training. Switch that feature on with `e_map.add_images_to_tensorboard()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_map.add_images_to_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project all dihedrals to the low-dimensional space..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_d_projection = e_map.encode(dihedrals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# define max clusters\n",
    "max_clusters = 5\n",
    "\n",
    "# remove unwanted clusters\n",
    "colors = cluster_ids.copy()\n",
    "colors[colors > max_clusters] = 0\n",
    "colors = colors.astype(int).astype(str)\n",
    "\n",
    "# plot\n",
    "px.scatter(\n",
    "    data_frame=pd.DataFrame(\n",
    "        {\n",
    "            \"x\": low_d_projection[:, 0],\n",
    "            \"y\": low_d_projection[:, 1],\n",
    "            \"color\": colors,\n",
    "        }\n",
    "    ),\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"color\",\n",
    "    opacity=0.5,\n",
    "    color_discrete_map={\n",
    "        \"0\": \"rgba(100, 100, 100, 0.2)\",\n",
    "    },\n",
    "    labels={\n",
    "        \"x\": \"x in a.u.\",\n",
    "        \"y\": \"y in a.u.\",\n",
    "        \"color\": \"cluster\",\n",
    "    },\n",
    "    width=500,\n",
    "    height=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above map points from different clusters (different colors) should be well separated. However, if you didn't change the parameters, they are probably not. Some of our parameter settings appear to be unsuitable. Let's see how we can find out what goes wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The `history` element returned by `e_map.train()` is an instance of `tf.keras.callbacks.History`, which contains the loss during the training steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.asarray(history.history[\"loss\"])\n",
    "\n",
    "px.line(\n",
    "    x=np.arange(len(loss)),\n",
    "    y=loss,\n",
    "    labels={\n",
    "        \"x\": \"training step\",\n",
    "        \"y\": \"loss\",\n",
    "    },\n",
    "    width=500,\n",
    "    height=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize-learning-with-tensorboard'></a>\n",
    "\n",
    "## Visualize Learning with TensorBoard\n",
    "\n",
    "### Running tensorboard on Google colab\n",
    "\n",
    "To use tensorboard in google colabs notebooks, you neet to first load the tensorboard extension\n",
    "\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "```\n",
    "\n",
    "And then activate it with:\n",
    "\n",
    "```python\n",
    "%tensorboard --logdir .\n",
    "```\n",
    "\n",
    "The next code cell contains these commands. Uncomment them and then continue.\n",
    "\n",
    "### Running tensorboard locally\n",
    "\n",
    "TensorBoard is a visualization tool from the machine learning library TensorFlow which is used by the EncoderMap package. During the dimensionality reduction step, when the neural network autoencoder is trained, several readings are saved in a TensorBoard format. All output files are saved to the path defined in `parameters.main_path`. Navigate to this location in a shell and start TensorBoard. Change the paramter Tensorboard to `True` to make Encodermap log to Tensorboard.\n",
    "\n",
    "In case you run this tutorial in the provided Docker container you can open a new console inside the container by typing the following command in a new system shell.\n",
    "```shell\n",
    "docker exec -it emap bash\n",
    "```\n",
    "Navigate to the location where all the runs are saved. e.g.:\n",
    "```shell\n",
    "cd notebooks_easy/runs/asp7/\n",
    "```\n",
    "Start TensorBoard in this directory with:\n",
    "```shell\n",
    "tensorboard --logdir .\n",
    "```\n",
    "\n",
    "You should now be able to open TensorBoard in your webbrowser on port 6006.  \n",
    "`0.0.0.0:6006` or `127.0.0.1:6006`\n",
    "\n",
    "In the SCALARS tab of TensorBoard you should see among other values the overall cost and different contributions to the cost. The two most important contributions are `auto_cost` and `distance_cost`. `auto_cost` indicates differences between the inputs and outputs of the autoencoder. `distance_cost` is the part of the cost function which compares pairwise distances in the input space and the low-dimensional (latent) space.\n",
    "\n",
    "**Fixing Reloading issues**\n",
    "Using Tensorboard we often encountered some issues while training multiple models and writing mutliple runs to Tensorboard's logdir. Reloading the data and event refreshing the web page did not display the data of the current run. We needed to kill tensorboard and restart it in order to see the new data. This issue was fixed by setting `reload_multifile` `True`.\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir . --reload_multifile True\n",
    "```\n",
    "\n",
    "\n",
    "In your case, probably the overall cost as well as the auto_cost and the distance_cost are still decreasing after all training iterations. This tells us that we can simply improve the result by increasing the number of training steps. The following cell contains the same code as above. Set a larger number of straining steps to improve the result (e.g. 3000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you're on Goole Colab, you can load the Tensorboard extension with:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "parameters = em.Parameters(\n",
    "    main_path=em.misc.run_path(\"runs/asp7\"),\n",
    "    n_steps=100,\n",
    "    dist_sig_parameters=(4.5, 12, 6, 1, 2, 6),\n",
    "    periodicity=2*pi,\n",
    "    l2_reg_constant=10,\n",
    "    summary_step=1,\n",
    "    tensorboard=True\n",
    ")\n",
    "\n",
    "# Instantiate the EncoderMap class\n",
    "e_map = em.EncoderMap(parameters, dihedrals)\n",
    "\n",
    "\n",
    "# this function returns rgba() values, that plotly.express.scatter understands\n",
    "def colors_from_cluster_ids(cluster_ids, max_clusters=10):\n",
    "    import plotly as plt\n",
    "    colors = np.full(shape=(len(cluster_ids), ), fill_value=\"rgba(125, 125, 125, 0.1)\")\n",
    "    # colors = np.full(shape=(len(cluster_ids), 4), fill_value=(.5, .5, .5, .1))\n",
    "    for i in range(2, max_clusters + 2):\n",
    "        where = np.where(cluster_ids == i)\n",
    "        color = plt.colors.DEFAULT_PLOTLY_COLORS[i - 2]\n",
    "        color = color.replace(\")\", \", 0.3)\").replace(\"rgb\", \"rgba\")\n",
    "        colors[where] = color\n",
    "    return colors\n",
    "\n",
    "# Logging images to Tensorboard can greatly reduce performance.\n",
    "# So they need to be specifically turned on\n",
    "# with the .add_images_to_tensorboard() method\n",
    "e_map.add_images_to_tensorboard(\n",
    "    data=dihedrals,\n",
    "    image_step=2,\n",
    "    plotly_scatter_kws={\n",
    "        'size_max': 1,\n",
    "        'color': colors_from_cluster_ids(cluster_ids, 5),\n",
    "    },\n",
    "    backend=\"plotly\",\n",
    "    save_to_disk=True,\n",
    ")\n",
    "\n",
    "history = e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The molecule conformations form different clusters (different colors) should be separated a bit better now. In TensorBoard you should see the cost curves for this new run. When the cost curve becomes more or less flat towards the end, longer training does not make sense.\n",
    "\n",
    "The resulting low-dimensional projection is probably still not very detailed and clusters are probably not well separated. Currently we use a regularization constant `parameters.l2_reg_constant = 10.0`. The regularization constant influences the \n",
    "complexity of the network and the map. A high regularization constant will result in a smooth map with little details. A small regularization constant will result in a rougher more detailed map.\n",
    "\n",
    "Go back to the previous cell and decrease the regularization constant (e.g. `parameters.l2_reg_constant = 0.001`). Play with different settings to improve the separation of the clusters in the map. Have a look at TensorBoard to see how the cost changes for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowd = e_map.encode(dihedrals)\n",
    "\n",
    "fig = px.scatter(\n",
    "    x=lowd[:, 0],\n",
    "    y=lowd[:, 1],\n",
    "    color=colors_from_cluster_ids(cluster_ids, 5),\n",
    "    height=500,\n",
    "    width=500,\n",
    "    size_max=0.1,\n",
    "    opacity=0.4,\n",
    "    labels={\n",
    "        \"x\": \"x in a.u.\",\n",
    "        \"y\": \"y in a.u.\",\n",
    "    },\n",
    ")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is what you can see in Tensorboard:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tensorboard_Cost.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tensorboard_Histograms.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tensorboard_Parameters.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tensorboard_Images.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load\n",
    "Once you are satisfied with your EncoderMap, you might want to save the result. The good news is: Encoder map automatically saves checkpoints during the training process in `parameters.main_path`. The frequency of writing checkpoints can be defined with `patameters.checkpoint_step`. Also, your selected parameters are saved in a file called `parameters.json`. Navigate to the driectory of your last run and open this `parameters.json` file in some text editor. You should find all the parameters that we have set so far. You also find some parameters which were not set by us specifically and where EncoderMap used its default values.\n",
    "\n",
    "Let's start by looking at the parameters from the last run and printing them in a nicely formatted table with the `.parameters` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parameters = em.Parameters.from_file('runs/asp7/run0/parameters.json')\n",
    "print(loaded_parameters.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can reload our trained network we need to save it manually, because the checkpoint step was set to 5000 and we did only write a checkpoint at 0 (random initial weights). We call `e_map.save()` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_map.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most recent run directory\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "latest_run_dir = Path(\"runs/asp7\").glob(\"run*\")\n",
    "latest_run_dir = sorted(latest_run_dir, key=lambda x: int(re.findall(r\"\\d+\", str(x))[0]))[0]\n",
    "loaded_e_map = em.EncoderMap.from_checkpoint(latest_run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finished with loading and we can for example use the loaded EncoderMap object to project data to the low_dimensional space and plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# define max clusters\n",
    "max_clusters = 5\n",
    "\n",
    "# remove unwanted clusters\n",
    "colors = cluster_ids.copy()\n",
    "colors[colors > max_clusters] = 0\n",
    "colors = colors.astype(int).astype(str)\n",
    "\n",
    "# plot\n",
    "px.scatter(\n",
    "    data_frame=pd.DataFrame(\n",
    "        {\n",
    "            \"x\": lowd[:, 0],\n",
    "            \"y\": lowd[:, 1],\n",
    "            \"color\": colors,\n",
    "        }\n",
    "    ),\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"color\",\n",
    "    opacity=0.5,\n",
    "    color_discrete_map={\n",
    "        \"0\": \"rgba(100, 100, 100, 0.2)\",\n",
    "    },\n",
    "    labels={\n",
    "        \"x\": \"x in a.u.\",\n",
    "        \"y\": \"y in a.u.\",\n",
    "        \"color\": \"cluster\",\n",
    "    },\n",
    "    width=500,\n",
    "    height=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='generate-molecular-conformations'></a>\n",
    "\n",
    "## Generate Molecular Conformations\n",
    "Already in the cube example, you have seen that with EncoderMap it is not only possible to project points to the low-dimensional space. Also, a projection of low-dimensional points into the high-dimensional space is possible. \n",
    "\n",
    "Here, we will use a tool form the EncoderMap library to interactively select a path in the low-dimensional map called. We will project points along this path into the high-dimensional dihedral space, and use these dihedrals to reconstruct molecular conformations. This can be very useful to explore the landscape an to see what changes occur in the molecular conformation going from one cluster to another.\n",
    "\n",
    "The next cell instantiates the `InteractivePlotting` class of EncoderMap. Inside the main plotting area, you can click on points and their corresponding molecular conformation is displayed in the right window. The `Trace` plot contains the high-dimensional data (in this case the dihedrals) that this point was projected from. Picking up the `Lasso` tool from the toolbar, you can draw a lasso selection around some points. Pressing `Cluster` afterwards will display 10 structures from all of the structures you selected. You can adjust this number with the `Size` slider.\n",
    "\n",
    "More interesting is the `Path` tool which can be used, when the density is displayed. With this tool you can generate molecular conformations from a path in the latent space. You don't need to pick up a tool from the toolbar to draw a path. Just switch to density with the `Density` button. After you have drawn your path, click `Generate` to generate the molecular conformations from the low-dimensional points that you just drew.\n",
    "\n",
    "In either case, hitting `Save` will sasve your cluster or path into the training directory of the EncoderMap class (where alsi Tensorboard stuff is put).\n",
    "\n",
    "Give the `InteractivePlotting` a try. We would like to hear your feedback at GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = em.InteractivePlotting(\n",
    "    e_map,\n",
    "    trajs=\"asp7.xtc\",\n",
    "    lowd_data=lowd,\n",
    "    highd_data=dihedrals,\n",
    "    top='asp7.pdb',\n",
    "    ball_and_stick=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As backbone dihedrals contain no information about the side-chains, only the backbone of the molecule can be reconstructed. \n",
    "In case the generated conformations change very abruptly it might be sensible to increase the regularization constant to obtain a smoother representation. If the generated conformations along a path are not changing at all, the regularization is probably to strong and prevents the network form generating different conformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we applied EncoderMap to a molecular system. You have learned how to monitor the EncoderMap training procedure with TensorBoard, how to restore previously saved EncoderMaps and how to generate Molecular conformations using the InteractivePlotting session."
   ]
  }
 ],
 "metadata": {
  "emap": "run",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
