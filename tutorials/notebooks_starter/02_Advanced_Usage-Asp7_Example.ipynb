{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asp7 Example - Advanced Usage\n",
    "\n",
    "Run this notebook on Google Colab:\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AG-Peter/encodermap/blob/main/tutorials/notebooks_starter/02_Advanced_Usage-Asp7_Example.ipynb)\n",
    "\n",
    "Find the documentation of EncoderMap:\n",
    "\n",
    "https://ag-peter.github.io/encodermap\n",
    "\n",
    "### For Google colab only:\n",
    "\n",
    "If you're on Google colab, please uncomment these lines and install EncoderMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T10:58:11.746245Z",
     "start_time": "2023-02-01T10:58:11.742519Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/install_encodermap_google_colab.sh\n",
    "# !sudo bash install_encodermap_google_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're on Google colab, you also want to download the Data we will use in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/notebooks_starter/asp7.csv\n",
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/notebooks_starter/asp7.pdb\n",
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/notebooks_starter/asp7.xtc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this tutorial we will use example data from a molecular dynamics simulation and learn more about advanced usage of EncoderMap. Encoder map can create low-dimensional maps of the vast conformational spaces of molecules. This allows easy identification of the most common molecular conformations and helps to understand the relations between these conformations. In this example, we will use data from a simulation of a simple peptide: hepta-aspartic-acid.\n",
    "\n",
    "First we need to import some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T08:17:54.859346Z",
     "start_time": "2022-06-01T08:17:48.770801Z"
    }
   },
   "outputs": [],
   "source": [
    "import encodermap as em\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "%config Completer.use_jedi=False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fix the random state of tensorflow for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load the input data. Different kinds of variables can be used to describe molecular conformations: e.g. Cartesian coordinates, distances, angles, dihedrals... In principle EncoderMap can deal with any of these inputs, however, some are better suited than others. The molecular conformation does not change when the molecule is translated or rotated. The chosen input variables should reflect that and be translationally and rotationally invariant. \n",
    "\n",
    "In this example we use the backbone dihedral angles phi and psi as input as they are translationally and rotationally invariant and describe the backbone of a protein/peptide very well.\n",
    "\n",
    "The \"asp7.csv\" file contains one column for each dihedral and one row for each frame of the trajectory. Additionally, the last column contains a cluster_id from a gromos clustering which we can later use for comparison. We can load this data using numpy.loadtxt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T08:17:55.039806Z",
     "start_time": "2022-06-01T08:17:54.860854Z"
    }
   },
   "outputs": [],
   "source": [
    "csv_path = \"asp7.csv\"\n",
    "data = np.loadtxt(csv_path, skiprows=1, delimiter=\",\")\n",
    "dihedrals = data[:, :-1]\n",
    "cluster_ids = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T08:19:18.256124Z",
     "start_time": "2022-06-01T08:19:18.126847Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nglview as nv\n",
    "import mdtraj as md\n",
    "traj = md.load('asp7.xtc', top='asp7.pdb')\n",
    "view = nv.show_mdtraj(traj)\n",
    "view.add_representation('hyperball')\n",
    "view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous example, we need to set some parameters. In contrast to the Cube example we now have periodic input data. The dihedral angles are in radians with a 2pi periodicity. We also set some further parameters but don't bother for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T12:07:46.150451Z",
     "start_time": "2022-03-16T12:07:45.560895Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = em.Parameters()\n",
    "parameters.main_path = em.misc.run_path(\"runs/asp7\")\n",
    "parameters.n_steps = 100\n",
    "parameters.dist_sig_parameters = (4.5, 12, 6, 1, 2, 6)\n",
    "parameters.periodicity = 2*pi\n",
    "parameters.l2_reg_constant = 10.0\n",
    "parameters.summary_step = 1\n",
    "parameters.tensorboard\n",
    "\n",
    "%matplotlib inline\n",
    "em.plot.distance_histogram(dihedrals[::10], \n",
    "                           parameters.periodicity, \n",
    "                           parameters.dist_sig_parameters,\n",
    "                           bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can run the dimensionality reduction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T12:07:48.695453Z",
     "start_time": "2022-03-16T12:07:48.573320Z"
    }
   },
   "outputs": [],
   "source": [
    "e_map = em.EncoderMap(parameters, dihedrals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The new tensorflow 2 version of EncoderMap allows you to also view the output of the latent space during the training. Switch that feature on with `e_map.add_images_to_tensorboard()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "e_map.add_images_to_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T12:08:45.680319Z",
     "start_time": "2022-03-16T12:07:48.823742Z"
    }
   },
   "outputs": [],
   "source": [
    "e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project all dihedrals to the low-dimensional space..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T12:08:48.867779Z",
     "start_time": "2022-03-16T12:08:48.802246Z"
    }
   },
   "outputs": [],
   "source": [
    "low_d_projection = e_map.encode(dihedrals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " and plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T12:08:50.169521Z",
     "start_time": "2022-03-16T12:08:50.092947Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# rgba color from cluster_id. All 1.0s are grey RGBA=(.5, .5, .5, .1)\n",
    "# the rest are colored with maptlotlib C0, C1, C2, ...\n",
    "def colors_from_cluster_ids(cluster_ids, max_clusters=10):\n",
    "    colors = np.full(shape=(len(cluster_ids), 4), fill_value=(.5, .5, .5, .1))\n",
    "    for i in range(2, max_clusters + 2):\n",
    "        where = np.where(cluster_ids == i)\n",
    "        color = (*mpl.colors.to_rgb(f'C{i - 2}'), 0.3)\n",
    "        colors[where] = color\n",
    "    return colors\n",
    "\n",
    "# define max clusters\n",
    "max_clusters = 5\n",
    "\n",
    "# create figure\n",
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(*low_d_projection.T, s=20, c=colors_from_cluster_ids(cluster_ids, max_clusters))\n",
    "\n",
    "# fake a legend, because using scatter with RGBA values will not produce a legend\n",
    "recs = []\n",
    "for i in range(max_clusters):\n",
    "    recs.append(mpl.patches.Rectangle((0, 0), 1, 1, fc=f\"C{i}\"))\n",
    "ax.legend(recs, range(max_clusters), loc=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above map points from different clusters (different colors) should be well separated. However, if you didn't change the parameters, they are probably not. Some of our parameter settings appear to be unsuitable. Let's see how we can find out what goes wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learning with TensorBoard\n",
    "\n",
    "### Running tensorboard on Google colab\n",
    "\n",
    "To use tensorboard in google colabs notebooks, you neet to first load the tensorboard extension\n",
    "\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "```\n",
    "\n",
    "And then activate it with:\n",
    "\n",
    "```python\n",
    "%tensorboard --logdir .\n",
    "```\n",
    "\n",
    "The next code cell contains these commands. Uncomment them and then continue.\n",
    "\n",
    "### Running tensorboard locally\n",
    "\n",
    "TensorBoard is a visualization tool from the machine learning library TensorFlow which is used by the EncoderMap package. During the dimensionality reduction step, when the neural network autoencoder is trained, several readings are saved in a TensorBoard format. All output files are saved to the path defined in `parameters.main_path`. Navigate to this location in a shell and start TensorBoard. Change the paramter Tensorboard to `True` to make Encodermap log to Tensorboard.\n",
    "\n",
    "In case you run this tutorial in the provided Docker container you can open a new console inside the container by typing the following command in a new system shell.\n",
    "```shell\n",
    "docker exec -it emap bash\n",
    "```\n",
    "Navigate to the location where all the runs are saved. e.g.:\n",
    "```shell\n",
    "cd notebooks_easy/runs/asp7/\n",
    "```\n",
    "Start TensorBoard in this directory with:\n",
    "```shell\n",
    "tensorboard --logdir .\n",
    "```\n",
    "\n",
    "You should now be able to open TensorBoard in your webbrowser on port 6006.  \n",
    "`0.0.0.0:6006` or `127.0.0.1:6006`\n",
    "\n",
    "In the SCALARS tab of TensorBoard you should see among other values the overall cost and different contributions to the cost. The two most important contributions are `auto_cost` and `distance_cost`. `auto_cost` indicates differences between the inputs and outputs of the autoencoder. `distance_cost` is the part of the cost function which compares pairwise distances in the input space and the low-dimensional (latent) space.\n",
    "\n",
    "**Fixing Reloading issues**\n",
    "Using Tensorboard we often encountered some issues while training multiple models and writing mutliple runs to Tensorboard's logdir. Reloading the data and event refreshing the web page did not display the data of the current run. We needed to kill tensorboard and restart it in order to see the new data. This issue was fixed by setting `reload_multifile` `True`.\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir . --reload_multifile True\n",
    "```\n",
    "\n",
    "\n",
    "In your case, probably the overall cost as well as the auto_cost and the distance_cost are still decreasing after all training iterations. This tells us that we can simply improve the result by increasing the number of training steps. The following cell contains the same code as above. Set a larger number of straining steps to improve the result (e.g. 3000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Goole colab, you can load the Tensorboard extension with:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-01T11:00:12.936864Z",
     "start_time": "2023-02-01T11:00:12.933714Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T08:20:37.666620Z",
     "start_time": "2022-06-01T08:20:37.488066Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = em.Parameters(\n",
    "    main_path=em.misc.run_path(\"runs/asp7\"),\n",
    "    n_steps=100,\n",
    "    dist_sig_parameters=(4.5, 12, 6, 1, 2, 6),\n",
    "    periodicity=2*pi,\n",
    "    l2_reg_constant=10,\n",
    "    summary_step=1,\n",
    "    tensorboard=True\n",
    ")\n",
    "\n",
    "e_map = em.EncoderMap(parameters, dihedrals)\n",
    "\n",
    "# Logging images to Tensorboard can greatly reduce performance.\n",
    "# So they need to be specifically turned on\n",
    "e_map.add_images_to_tensorboard(dihedrals, 2,\n",
    "                                scatter_kws={'s': 50, 'c': colors_from_cluster_ids(cluster_ids, 5)}\n",
    "                               )\n",
    "\n",
    "e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The molecule conformations form different clusters (different colors) should be separated a bit better now. In TensorBoard you should see the cost curves for this new run. When the cost curve becomes more or less flat towards the end, longer training does not make sense.\n",
    "\n",
    "The resulting low-dimensional projection is probably still not very detailed and clusters are probably not well separated. Currently we use a regularization constant `parameters.l2_reg_constant = 10.0`. The regularization constant influences the \n",
    "complexity of the network and the map. A high regularization constant will result in a smooth map with little details. A small regularization constant will result in a rougher more detailed map.\n",
    "\n",
    "Go back to the previous cell and decrease the regularization constant (e.g. `parameters.l2_reg_constant = 0.001`). Play with different settings to improve the separation of the clusters in the map. Have a look at TensorBoard to see how the cost changes for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.close('all')\n",
    "plt.scatter(*e_map.encode(dihedrals).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is what you can see in Tensorboard:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tensorboard_Cost.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tensorboard_Histograms.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tensorboard_Parameters.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Tensorboard_Images.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load\n",
    "Once you are satisfied with your EncoderMap, you might want to save the result. The good news is: Encoder map automatically saves checkpoints during the training process in `parameters.main_path`. The frequency of writing checkpoints can be defined with `patameters.checkpoint_step`. Also, your selected parameters are saved in a file called `parameters.json`. Navigate to the driectory of your last run and open this `parameters.json` file in some text editor. You should find all the parameters that we have set so far. You also find some parameters which were not set by us specifically and where EncoderMap used its default values.\n",
    "\n",
    "Let's start by looking at the parameters from the last run and printing them in a nicely formatted table with the `.parameters` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parameters = em.Parameters.from_file('runs/asp7/run0/parameters.json')\n",
    "print(loaded_parameters.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can reload our trained network we need to save it manually, because the checkpoint step was set to 5000 and we did only write a checkpoint at 0 (random initial weights). We call `e_map.save()` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_map.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T12:09:12.018611Z",
     "start_time": "2022-03-16T12:09:11.944377Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the most recent file\n",
    "import os\n",
    "from pathlib import Path\n",
    "latest_checkpoint_file = str(list(sorted(Path(\"runs/asp7\").rglob(\"*model*\"), key=os.path.getmtime, reverse=True))[0]).rstrip(\"_decoder\").rstrip(\"_encoder\")\n",
    "print(latest_checkpoint_file)\n",
    "loaded_e_map = em.EncoderMap.from_checkpoint(latest_checkpoint_file, overwrite_tensorboard_bool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finished with loading and we can for example use the loaded EncoderMap object to project data to the low_dimensional space and plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T12:09:16.857966Z",
     "start_time": "2022-03-16T12:09:16.765457Z"
    }
   },
   "outputs": [],
   "source": [
    "low_d_projection = e_map.encode(dihedrals)\n",
    "\n",
    "# Plotting:\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(low_d_projection[:, 0], low_d_projection[:, 1], linestyle=\"\", marker=\".\",\n",
    "         markersize=5, color=\"0.7\", alpha=0.1)\n",
    "for i in range(9):\n",
    "    mask = cluster_ids == i + 1\n",
    "    ax.plot(low_d_projection[:, 0][mask], low_d_projection[:, 1][mask], label=str(i),\n",
    "             linestyle=\"\", marker=\".\", markersize=5, alpha=0.3)\n",
    "\n",
    "legend = ax.legend()\n",
    "for lh in legend.legendHandles:\n",
    "    if hasattr(lh, \"legmarker\"):\n",
    "        lh.legmarker.set_alpha(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Molecular Conformations\n",
    "Already in the cube example, you have seen that with EncoderMap it is not only possible to project points to the low-dimensional space. Also, a projection of low-dimensional points into the high-dimensional space is possible. \n",
    "\n",
    "Here, we will use a tool form the EncoderMap library to interactively select a path in the low-dimensional map. We will project points along this path into the high-dimensional dihedral space, and use these dihedrals to reconstruct molecular conformations. This can be very useful to explore the landscape an to see what changes in the molecular conformation going from one cluster to another.\n",
    "\n",
    "The next cell instantiates a class with which you can interact with the low-dimensional projection of the Autoencoder. You can select clusters with the `Polygon`, `Ellipse,`, `Rectangle` and `Lasso` tools. The clusters will be selected fron the input conformations in `asp7.xtc`.\n",
    "\n",
    "More interesting is the `Bezier` and `Path` tool. With these you can generate molecular conformations from a path in the latent space.\n",
    "\n",
    "Click `Set Points` and then `Write`/`Generate` to make your own clusters/paths. You can have a look at what you selected using the `sess.view` attribute of the InteractivePlotting class. For this you need to have nglview installed.\n",
    "\n",
    "Give the InteractivePlotting a try. We would like to hear your feedback at GitHub.\n",
    "\n",
    "**Note:** This notebook uses a non-interactive matploltib backend to render for web pages. Switch to an interactive backend by using either:\n",
    "\n",
    "```python\n",
    "%matploltib qt5\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```python\n",
    "%matploltib notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T08:20:31.830392Z",
     "start_time": "2022-06-01T08:20:30.113292Z"
    }
   },
   "outputs": [],
   "source": [
    "#%matploltib notebook\n",
    "sess = em.InteractivePlotting(e_map, \"asp7.xtc\", data=low_d_projection,\n",
    "                              top='asp7.pdb', scatter_kws={'s': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-16T12:11:43.763013Z",
     "start_time": "2022-03-16T12:11:42.357328Z"
    }
   },
   "outputs": [],
   "source": [
    "sess.view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As backbone dihedrals contain no information about the side-chains, only the backbone of the molecule can be reconstructed. \n",
    "In case the generated conformations change very abruptly it might be sensible to increase the regularization constant to obtain a smoother representation. If the generated conformations along a path are not changing at all, the regularization is probably to strong and prevents the network form generating different conformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we applied EncoderMap to a molecular system. You have learned how to monitor the EncoderMap training procedure with TensorBoard, how to restore previously saved EncoderMaps and how to generate Molecular conformations using the path selection tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
