
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Models &#8212; encodermap 3.0.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/bootstrap.css?digest=796348d33e8b1d947c94" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=796348d33e8b1d947c94" rel="stylesheet">

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=796348d33e8b1d947c94" rel="stylesheet">
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94">
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'reference/models';</script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Layers" href="layers.html" />
    <link rel="prev" title="Featurization" href="featurization.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/logo_cube_300.png" class="logo__image only-light" alt="Logo image">
    <img src="../_static/logo_cube_300.png" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../getting_started/index.html">
                        Getting started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../user_guide_and_examples/index.html">
                        User Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="index.html">
                        API reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../whatsnew/index.html">
                        Changelog
                      </a>
                    </li>
                
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      
        <div class="navbar-end-item navbar-persistent--container">
          
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
        </div>
      
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/Ag-Peter/encodermap" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>


  
  
    <div class="navbar-persistent--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
    </div>
  

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../getting_started/index.html">
                        Getting started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../user_guide_and_examples/index.html">
                        User Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="index.html">
                        API reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../whatsnew/index.html">
                        Changelog
                      </a>
                    </li>
                
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
</button>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          <a href="https://github.com/Ag-Peter/encodermap" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-toggle="tooltip"><span><i class="fa-brands fa-square-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="trajectory_classes.html">Trajectory classes</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="autoencoder_classes.html">Neural Network model building and learning</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="parameter_classes.html">Parameter Classes</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="featurization.html">Featurization</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">Models</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="layers.html">Layers</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="loss_functions.html">Loss functions</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="simple">
</ul>
</li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

  
  <div id="rtd-footer-container"></div>

      </div>
      <main id="main-content" class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  <section id="models">
<span id="id1"></span><h1>Models<a class="headerlink" href="#models" title="Permalink to this heading">#</a></h1>
<span class="target" id="module-encodermap.models.models"></span><p>ToDo:
* Add some nice images to the plot_model of the functional model.</p>
<dl class="py class">
<dt class="sig sig-object py" id="encodermap.models.models.ADCSequentialModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">encodermap.models.models.</span></span><span class="sig-name descname"><span class="pre">ADCSequentialModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#ADCSequentialModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.ADCSequentialModel" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encodermap.models.models.SequentialModel" title="encodermap.models.models.SequentialModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">SequentialModel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.ADCSequentialModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#ADCSequentialModel.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.ADCSequentialModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Calls the model on new inputs and returns the outputs as tensors.</p>
<p>In this case <cite>call()</cite> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<p>Note: This method should not be called directly. It is only meant to be
overridden when subclassing <cite>tf.keras.Model</cite>.
To call a model on an input, always use the <cite>__call__()</cite> method,
i.e. <cite>model(inputs)</cite>, which relies on the underlying <cite>call()</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – Input tensor, or dict/list/tuple of input tensors.</p></li>
<li><p><strong>training</strong> – Boolean or boolean scalar tensor, indicating whether to
run the <cite>Network</cite> in training mode or inference mode.</p></li>
<li><p><strong>mask</strong> – A mask or list of masks. A mask can be either a boolean tensor
or None (no mask). For more details, check the guide
[here](<a class="reference external" href="https://www.tensorflow.org/guide/keras/masking_and_padding">https://www.tensorflow.org/guide/keras/masking_and_padding</a>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor if there is a single output, or
a list of tensors if there are more than one outputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.ADCSequentialModel.call_and_map_back">
<span class="sig-name descname"><span class="pre">call_and_map_back</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distances</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">angles</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dihedrals</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cartesians</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">splits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">side_dihedrals</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#ADCSequentialModel.call_and_map_back"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.ADCSequentialModel.call_and_map_back" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.ADCSequentialModel.train_step">
<span class="sig-name descname"><span class="pre">train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#ADCSequentialModel.train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.ADCSequentialModel.train_step" title="Permalink to this definition">#</a></dt>
<dd><p>Overwrites the normal train_step. What is different?</p>
<p>Not much. Even the provided data is expected to be a tuple of (data, classes) (x, y) in classification tasks.
The data is unpacked and y is discarded, because the Autoencoder Model is a regression task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<em>tuple</em>) – The (x, y) data of this train step.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="encodermap.models.models.FunctionalModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">encodermap.models.models.</span></span><span class="sig-name descname"><span class="pre">FunctionalModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#FunctionalModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.FunctionalModel" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.FunctionalModel.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#FunctionalModel.compile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.FunctionalModel.compile" title="Permalink to this definition">#</a></dt>
<dd><p>Configures the model for training.</p>
<p>Example:</p>
<p><a href="#id2"><span class="problematic" id="id3">``</span></a><a href="#id4"><span class="problematic" id="id5">`</span></a>python
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),</p>
<blockquote>
<div><p>loss=tf.keras.losses.BinaryCrossentropy(),
metrics=[tf.keras.metrics.BinaryAccuracy(),</p>
<blockquote>
<div><p>tf.keras.metrics.FalseNegatives()])</p>
</div></blockquote>
</div></blockquote>
<p><a href="#id6"><span class="problematic" id="id7">``</span></a><a href="#id8"><span class="problematic" id="id9">`</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> – String (name of optimizer) or optimizer instance. See
<cite>tf.keras.optimizers</cite>.</p></li>
<li><p><strong>loss</strong> – Loss function. May be a string (name of loss function), or
a <cite>tf.keras.losses.Loss</cite> instance. See <cite>tf.keras.losses</cite>. A loss
function is any callable with the signature <cite>loss = fn(y_true,
y_pred)</cite>, where <cite>y_true</cite> are the ground truth values, and
<cite>y_pred</cite> are the model’s predictions.
<cite>y_true</cite> should have shape
<cite>(batch_size, d0, .. dN)</cite> (except in the case of
sparse loss functions such as
sparse categorical crossentropy which expects integer arrays of
shape <cite>(batch_size, d0, .. dN-1)</cite>).
<cite>y_pred</cite> should have shape <cite>(batch_size, d0, .. dN)</cite>.
The loss function should return a float tensor.
If a custom <cite>Loss</cite> instance is
used and reduction is set to <cite>None</cite>, return value has shape
<cite>(batch_size, d0, .. dN-1)</cite> i.e. per-sample or per-timestep loss
values; otherwise, it is a scalar. If the model has multiple
outputs, you can use a different loss on each output by passing a
dictionary or a list of losses. The loss value that will be
minimized by the model will then be the sum of all individual
losses, unless <cite>loss_weights</cite> is specified.</p></li>
<li><p><strong>metrics</strong> – List of metrics to be evaluated by the model during
training and testing. Each of this can be a string (name of a
built-in function), function or a <cite>tf.keras.metrics.Metric</cite>
instance. See <cite>tf.keras.metrics</cite>. Typically you will use
<cite>metrics=[‘accuracy’]</cite>.
A function is any callable with the signature <cite>result = fn(y_true,
y_pred)</cite>. To specify different metrics for different outputs of a
multi-output model, you could also pass a dictionary, such as
<cite>metrics={‘output_a’:’accuracy’, ‘output_b’:[‘accuracy’, ‘mse’]}</cite>.
You can also pass a list to specify a metric or a list of metrics
for each output, such as
<cite>metrics=[[‘accuracy’], [‘accuracy’, ‘mse’]]</cite>
or <cite>metrics=[‘accuracy’, [‘accuracy’, ‘mse’]]</cite>. When you pass the
strings ‘accuracy’ or ‘acc’, we convert this to one of
<cite>tf.keras.metrics.BinaryAccuracy</cite>,
<cite>tf.keras.metrics.CategoricalAccuracy</cite>,
<cite>tf.keras.metrics.SparseCategoricalAccuracy</cite> based on the shapes
of the targets and of the model output. We do a similar
conversion for the strings ‘crossentropy’ and ‘ce’ as well.
The metrics passed here are evaluated without sample weighting; if
you would like sample weighting to apply, you can specify your
metrics via the <cite>weighted_metrics</cite> argument instead.</p></li>
<li><p><strong>loss_weights</strong> – Optional list or dictionary specifying scalar
coefficients (Python floats) to weight the loss contributions of
different model outputs. The loss value that will be minimized by
the model will then be the <em>weighted sum</em> of all individual
losses, weighted by the <cite>loss_weights</cite> coefficients.  If a list,
it is expected to have a 1:1 mapping to the model’s outputs. If a
dict, it is expected to map output names (strings) to scalar
coefficients.</p></li>
<li><p><strong>weighted_metrics</strong> – List of metrics to be evaluated and weighted by
<cite>sample_weight</cite> or <cite>class_weight</cite> during training and testing.</p></li>
<li><p><strong>run_eagerly</strong> – Bool. Defaults to <cite>False</cite>. If <cite>True</cite>, this <cite>Model</cite>’s
logic will not be wrapped in a <cite>tf.function</cite>. Recommended to leave
this as <cite>None</cite> unless your <cite>Model</cite> cannot be run inside a
<cite>tf.function</cite>. <cite>run_eagerly=True</cite> is not supported when using
<cite>tf.distribute.experimental.ParameterServerStrategy</cite>.</p></li>
<li><p><strong>steps_per_execution</strong> – Int. Defaults to 1. The number of batches to
run during each <cite>tf.function</cite> call. Running multiple batches
inside a single <cite>tf.function</cite> call can greatly improve performance
on TPUs or small models with a large Python overhead. At most, one
full epoch will be run each execution. If a number larger than the
size of the epoch is passed, the execution will be truncated to
the size of the epoch. Note that if <cite>steps_per_execution</cite> is set
to <cite>N</cite>, <cite>Callback.on_batch_begin</cite> and <cite>Callback.on_batch_end</cite>
methods will only be called every <cite>N</cite> batches (i.e. before/after
each <cite>tf.function</cite> execution).</p></li>
<li><p><strong>jit_compile</strong> – If <cite>True</cite>, compile the model training step with XLA.
[XLA](<a class="reference external" href="https://www.tensorflow.org/xla">https://www.tensorflow.org/xla</a>) is an optimizing compiler
for machine learning.
<cite>jit_compile</cite> is not enabled for by default.
This option cannot be enabled with <cite>run_eagerly=True</cite>.
Note that <cite>jit_compile=True</cite>
may not necessarily work for all models.
For more information on supported operations please refer to the
[XLA documentation](<a class="reference external" href="https://www.tensorflow.org/xla">https://www.tensorflow.org/xla</a>).
Also refer to
[known XLA issues](<a class="reference external" href="https://www.tensorflow.org/xla/known_issues">https://www.tensorflow.org/xla/known_issues</a>)
for more details.</p></li>
<li><p><strong>**kwargs</strong> – Arguments supported for backwards compatibility only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.FunctionalModel.decoder">
<span class="sig-name descname"><span class="pre">decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#FunctionalModel.decoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.FunctionalModel.decoder" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.FunctionalModel.encoder">
<span class="sig-name descname"><span class="pre">encoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#FunctionalModel.encoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.FunctionalModel.encoder" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.FunctionalModel.get_loss">
<span class="sig-name descname"><span class="pre">get_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#FunctionalModel.get_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.FunctionalModel.get_loss" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.FunctionalModel.train_step">
<span class="sig-name descname"><span class="pre">train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#FunctionalModel.train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.FunctionalModel.train_step" title="Permalink to this definition">#</a></dt>
<dd><p>The logic for one training step.</p>
<p>This method can be overridden to support custom training logic.
For concrete examples of how to override this method see
[Customizing what happens in fit](
<a class="reference external" href="https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit">https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit</a>).
This method is called by <cite>Model.make_train_function</cite>.</p>
<p>This method should contain the mathematical logic for one step of
training.  This typically includes the forward pass, loss calculation,
backpropagation, and metric updates.</p>
<p>Configuration details for <em>how</em> this logic is run (e.g. <cite>tf.function</cite>
and <cite>tf.distribute.Strategy</cite> settings), should be left to
<cite>Model.make_train_function</cite>, which can also be overridden.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> – A nested structure of <a href="#id10"><span class="problematic" id="id11">`</span></a>Tensor`s.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A <cite>dict</cite> containing values that will be passed to
<cite>tf.keras.callbacks.CallbackList.on_train_batch_end</cite>. Typically, the
values of the <cite>Model</cite>’s metrics are returned. Example:
<cite>{‘loss’: 0.2, ‘accuracy’: 0.7}</cite>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="encodermap.models.models.SequentialModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">encodermap.models.models.</span></span><span class="sig-name descname"><span class="pre">SequentialModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SequentialModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SequentialModel" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.SequentialModel.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SequentialModel.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SequentialModel.build" title="Permalink to this definition">#</a></dt>
<dd><p>Builds the model based on input shapes received.</p>
<p>This is to be used for subclassed models, which do not know at
instantiation time what their inputs look like.</p>
<p>This method only exists for users who want to call <cite>model.build()</cite> in a
standalone way (as a substitute for calling the model on real data to
build it). It will never be called by the framework (and thus it will
never throw unexpected errors in an unrelated workflow).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Single tuple, <cite>TensorShape</cite> instance, or list/dict of
shapes, where shapes are tuples, integers, or <cite>TensorShape</cite>
instances.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ValueError</strong> – <ol class="arabic simple">
<li><p>In case of invalid user-provided data (not of type tuple,
       list, <cite>TensorShape</cite>, or dict).
    2. If the model requires call arguments that are agnostic
       to the input shapes (positional or keyword arg in call
       signature).
    3. If not all layers were properly built.
    4. If float type inputs are not supported within the layers.</p></li>
</ol>
</p></li>
<li><p><strong>In each</strong><strong> of </strong><strong>these cases</strong><strong>, </strong><strong>the user should build their model by calling</strong> – </p></li>
<li><p><strong>it on real tensor data.</strong> – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.SequentialModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SequentialModel.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SequentialModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Calls the model on new inputs and returns the outputs as tensors.</p>
<p>In this case <cite>call()</cite> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<p>Note: This method should not be called directly. It is only meant to be
overridden when subclassing <cite>tf.keras.Model</cite>.
To call a model on an input, always use the <cite>__call__()</cite> method,
i.e. <cite>model(inputs)</cite>, which relies on the underlying <cite>call()</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – Input tensor, or dict/list/tuple of input tensors.</p></li>
<li><p><strong>training</strong> – Boolean or boolean scalar tensor, indicating whether to
run the <cite>Network</cite> in training mode or inference mode.</p></li>
<li><p><strong>mask</strong> – A mask or list of masks. A mask can be either a boolean tensor
or None (no mask). For more details, check the guide
[here](<a class="reference external" href="https://www.tensorflow.org/guide/keras/masking_and_padding">https://www.tensorflow.org/guide/keras/masking_and_padding</a>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor if there is a single output, or
a list of tensors if there are more than one outputs.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.SequentialModel.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SequentialModel.compile"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SequentialModel.compile" title="Permalink to this definition">#</a></dt>
<dd><p>Configures the model for training.</p>
<p>Example:</p>
<p><a href="#id12"><span class="problematic" id="id13">``</span></a><a href="#id14"><span class="problematic" id="id15">`</span></a>python
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),</p>
<blockquote>
<div><p>loss=tf.keras.losses.BinaryCrossentropy(),
metrics=[tf.keras.metrics.BinaryAccuracy(),</p>
<blockquote>
<div><p>tf.keras.metrics.FalseNegatives()])</p>
</div></blockquote>
</div></blockquote>
<p><a href="#id16"><span class="problematic" id="id17">``</span></a><a href="#id18"><span class="problematic" id="id19">`</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> – String (name of optimizer) or optimizer instance. See
<cite>tf.keras.optimizers</cite>.</p></li>
<li><p><strong>loss</strong> – Loss function. May be a string (name of loss function), or
a <cite>tf.keras.losses.Loss</cite> instance. See <cite>tf.keras.losses</cite>. A loss
function is any callable with the signature <cite>loss = fn(y_true,
y_pred)</cite>, where <cite>y_true</cite> are the ground truth values, and
<cite>y_pred</cite> are the model’s predictions.
<cite>y_true</cite> should have shape
<cite>(batch_size, d0, .. dN)</cite> (except in the case of
sparse loss functions such as
sparse categorical crossentropy which expects integer arrays of
shape <cite>(batch_size, d0, .. dN-1)</cite>).
<cite>y_pred</cite> should have shape <cite>(batch_size, d0, .. dN)</cite>.
The loss function should return a float tensor.
If a custom <cite>Loss</cite> instance is
used and reduction is set to <cite>None</cite>, return value has shape
<cite>(batch_size, d0, .. dN-1)</cite> i.e. per-sample or per-timestep loss
values; otherwise, it is a scalar. If the model has multiple
outputs, you can use a different loss on each output by passing a
dictionary or a list of losses. The loss value that will be
minimized by the model will then be the sum of all individual
losses, unless <cite>loss_weights</cite> is specified.</p></li>
<li><p><strong>metrics</strong> – List of metrics to be evaluated by the model during
training and testing. Each of this can be a string (name of a
built-in function), function or a <cite>tf.keras.metrics.Metric</cite>
instance. See <cite>tf.keras.metrics</cite>. Typically you will use
<cite>metrics=[‘accuracy’]</cite>.
A function is any callable with the signature <cite>result = fn(y_true,
y_pred)</cite>. To specify different metrics for different outputs of a
multi-output model, you could also pass a dictionary, such as
<cite>metrics={‘output_a’:’accuracy’, ‘output_b’:[‘accuracy’, ‘mse’]}</cite>.
You can also pass a list to specify a metric or a list of metrics
for each output, such as
<cite>metrics=[[‘accuracy’], [‘accuracy’, ‘mse’]]</cite>
or <cite>metrics=[‘accuracy’, [‘accuracy’, ‘mse’]]</cite>. When you pass the
strings ‘accuracy’ or ‘acc’, we convert this to one of
<cite>tf.keras.metrics.BinaryAccuracy</cite>,
<cite>tf.keras.metrics.CategoricalAccuracy</cite>,
<cite>tf.keras.metrics.SparseCategoricalAccuracy</cite> based on the shapes
of the targets and of the model output. We do a similar
conversion for the strings ‘crossentropy’ and ‘ce’ as well.
The metrics passed here are evaluated without sample weighting; if
you would like sample weighting to apply, you can specify your
metrics via the <cite>weighted_metrics</cite> argument instead.</p></li>
<li><p><strong>loss_weights</strong> – Optional list or dictionary specifying scalar
coefficients (Python floats) to weight the loss contributions of
different model outputs. The loss value that will be minimized by
the model will then be the <em>weighted sum</em> of all individual
losses, weighted by the <cite>loss_weights</cite> coefficients.  If a list,
it is expected to have a 1:1 mapping to the model’s outputs. If a
dict, it is expected to map output names (strings) to scalar
coefficients.</p></li>
<li><p><strong>weighted_metrics</strong> – List of metrics to be evaluated and weighted by
<cite>sample_weight</cite> or <cite>class_weight</cite> during training and testing.</p></li>
<li><p><strong>run_eagerly</strong> – Bool. Defaults to <cite>False</cite>. If <cite>True</cite>, this <cite>Model</cite>’s
logic will not be wrapped in a <cite>tf.function</cite>. Recommended to leave
this as <cite>None</cite> unless your <cite>Model</cite> cannot be run inside a
<cite>tf.function</cite>. <cite>run_eagerly=True</cite> is not supported when using
<cite>tf.distribute.experimental.ParameterServerStrategy</cite>.</p></li>
<li><p><strong>steps_per_execution</strong> – Int. Defaults to 1. The number of batches to
run during each <cite>tf.function</cite> call. Running multiple batches
inside a single <cite>tf.function</cite> call can greatly improve performance
on TPUs or small models with a large Python overhead. At most, one
full epoch will be run each execution. If a number larger than the
size of the epoch is passed, the execution will be truncated to
the size of the epoch. Note that if <cite>steps_per_execution</cite> is set
to <cite>N</cite>, <cite>Callback.on_batch_begin</cite> and <cite>Callback.on_batch_end</cite>
methods will only be called every <cite>N</cite> batches (i.e. before/after
each <cite>tf.function</cite> execution).</p></li>
<li><p><strong>jit_compile</strong> – If <cite>True</cite>, compile the model training step with XLA.
[XLA](<a class="reference external" href="https://www.tensorflow.org/xla">https://www.tensorflow.org/xla</a>) is an optimizing compiler
for machine learning.
<cite>jit_compile</cite> is not enabled for by default.
This option cannot be enabled with <cite>run_eagerly=True</cite>.
Note that <cite>jit_compile=True</cite>
may not necessarily work for all models.
For more information on supported operations please refer to the
[XLA documentation](<a class="reference external" href="https://www.tensorflow.org/xla">https://www.tensorflow.org/xla</a>).
Also refer to
[known XLA issues](<a class="reference external" href="https://www.tensorflow.org/xla/known_issues">https://www.tensorflow.org/xla/known_issues</a>)
for more details.</p></li>
<li><p><strong>**kwargs</strong> – Arguments supported for backwards compatibility only.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.SequentialModel.decoder">
<span class="sig-name descname"><span class="pre">decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SequentialModel.decoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SequentialModel.decoder" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.SequentialModel.encoder">
<span class="sig-name descname"><span class="pre">encoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SequentialModel.encoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SequentialModel.encoder" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.SequentialModel.train_step">
<span class="sig-name descname"><span class="pre">train_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SequentialModel.train_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SequentialModel.train_step" title="Permalink to this definition">#</a></dt>
<dd><p>Overwrites the normal train_step. What is different?</p>
<p>Not much. Even the provided data is expected to be a tuple of (data, classes) (x, y) in classification tasks.
The data is unpacked and y is discarded, because the Autoencoder Model is a regression task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<em>tuple</em>) – The (x, y) data of this train step.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="encodermap.models.models.Sparse">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">encodermap.models.models.</span></span><span class="sig-name descname"><span class="pre">Sparse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#Sparse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.Sparse" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dense</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.Sparse.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#Sparse.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.Sparse.call" title="Permalink to this definition">#</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first
invocation, wrapping the creation of variables or other resources in
<cite>tf.init_scope()</cite>).  It is recommended to create state, including
<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>
<blockquote>
<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>
</div></blockquote>
<p>called automatically before <cite>call()</cite> executes for the first time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – <p>Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul>
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as
tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite>
only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</p></li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul>
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask
generated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come
from a layer that generated a corresponding mask, i.e. if it came
from a Keras layer with masking support).</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="encodermap.models.models.SparseFunctionalModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">encodermap.models.models.</span></span><span class="sig-name descname"><span class="pre">SparseFunctionalModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SparseFunctionalModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SparseFunctionalModel" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#encodermap.models.models.FunctionalModel" title="encodermap.models.models.FunctionalModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionalModel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.SparseFunctionalModel.get_loss">
<span class="sig-name descname"><span class="pre">get_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SparseFunctionalModel.get_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SparseFunctionalModel.get_loss" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="encodermap.models.models.SparseModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">encodermap.models.models.</span></span><span class="sig-name descname"><span class="pre">SparseModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SparseModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SparseModel" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="encodermap.models.models.SparseModel.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sparse_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#SparseModel.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.SparseModel.call" title="Permalink to this definition">#</a></dt>
<dd><p>Calls the model on new inputs and returns the outputs as tensors.</p>
<p>In this case <cite>call()</cite> just reapplies
all ops in the graph to the new inputs
(e.g. build a new computational graph from the provided inputs).</p>
<p>Note: This method should not be called directly. It is only meant to be
overridden when subclassing <cite>tf.keras.Model</cite>.
To call a model on an input, always use the <cite>__call__()</cite> method,
i.e. <cite>model(inputs)</cite>, which relies on the underlying <cite>call()</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – Input tensor, or dict/list/tuple of input tensors.</p></li>
<li><p><strong>training</strong> – Boolean or boolean scalar tensor, indicating whether to
run the <cite>Network</cite> in training mode or inference mode.</p></li>
<li><p><strong>mask</strong> – A mask or list of masks. A mask can be either a boolean tensor
or None (no mask). For more details, check the guide
[here](<a class="reference external" href="https://www.tensorflow.org/guide/keras/masking_and_padding">https://www.tensorflow.org/guide/keras/masking_and_padding</a>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor if there is a single output, or
a list of tensors if there are more than one outputs.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="encodermap.models.models.gen_functional_model">
<span class="sig-prename descclassname"><span class="pre">encodermap.models.models.</span></span><span class="sig-name descname"><span class="pre">gen_functional_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reload_layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#gen_functional_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.gen_functional_model" title="Permalink to this definition">#</a></dt>
<dd><p>Builds a model to specification of parameters using the functional API.</p>
<p>The functional API is much more flexible than the sequential API, in that models with multiple inputs and outputs
can be defined. Custom-layers and sub-models can be intermixed. In EncoderMap’s case the functional API is used to
build the AngleDihedralCartesianAutoencoder, which takes input data in form of a tf.data.Dataset with:</p>
<blockquote>
<div><ul class="simple">
<li><p>backbone_angles (angles between C, CA, N - atoms in the backbone).</p></li>
<li><p>backbone_torsions (dihedral angles in the backbone, commonly known as omega, phi, psi).</p></li>
<li><p>cartesian_coordinates (coordinates of the C, CA, N backbone atoms. This data has ndim 3, the other have ndim 2).</p></li>
<li><p>backbone_distances (distances between the C, CA, N backbone atoms).</p></li>
<li><p>sidechain_torsions (dihedral angles in the sidechain, commonly known as chi1, chi2, chi3, chi4, chi5).</p></li>
</ul>
</div></blockquote>
<p>Packing and unpacking that data in the correct manner is important. Make sure to double check whether you are using
angles or dihedrals. A simple print of the shape can be enough.</p>
<p>In the functional model all operations are tf.keras.layers, meaning that the projection onto a unit_circle that
the <cite>SequentialModel</cite> does in its <cite>call()</cite> method needs to be a layer. The FunctionalModel consist of 5 main parts:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt>Angle Inputs: The provided dataset is unpacked and the periodic data of the angles is projected onto</dt><dd><p>a unit-circle. If the angles are in gradians, they will also be normalized into a [-pi, pi) interval.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Autoencoder: The trainable part of the network consists of the Autoencoder part build to the specifications</dt><dd><p>in the provided parameters. Here, Dense layers are stacked. Only the angles and torsions are fed into the
Autoencoder. The Distances and Cartesians are used later.</p>
</dd>
</dl>
</li>
<li><p>Angle Outputs: The angles are recalculated from their unit-circle inputs.</p></li>
<li><dl class="simple">
<dt>Back-Mapping. The backmapping layer takes backbone_angles and backbone_dihedrals, backbone_distances to</dt><dd><p>calculate new cartesian coordinates.</p>
</dd>
</dl>
</li>
<li><p>Pairwise Distances: The pairwise distances of the input cartesians and the back-mapped cartesians are calculated.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dataset</strong> (<em>tf.data.Dataset</em>) – The dataset with the data in the order given in the explanation.</p></li>
<li><p><strong>parameters</strong> (<em>Union</em><em>[</em><em>em.ADCParameters</em><em>, </em><em>None</em><em>]</em><em>, </em><em>optional</em>) – The parameters to be used to build the network.
If None is provided the default parameters in encodermap.ADCParameters.defaults
is used. You can look at the defaults with print(em.ADCParameters.defaults_description()). Defaults to None.</p></li>
<li><p><strong>reload_layers</strong> (<em>Union</em><em>[</em><em>None</em><em>, </em><em>list</em><em>]</em><em>, </em><em>optional</em>) – List of layers that will be reloaded when reloading the model from
disk. Defaults to None, when a new model should be built.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>AssertionError</strong> – AssertionErrors will be raised when the input data is not formatted correctly.
    This means, if len(cartesians) != len(distances) - 1, or len(cartesians) != len(angles) - 2.
    This can also mean, the input dataset is not packed correctly. Please keep the order specified above.
    This can also mean, that the provided protein is not linear (branched, circular, …).</p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A subclass of tf.keras.Model build with specified parameters.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>em.FunctionalModel</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="encodermap.models.models.gen_sequential_model">
<span class="sig-prename descclassname"><span class="pre">encodermap.models.models.</span></span><span class="sig-name descname"><span class="pre">gen_sequential_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">parameters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/encodermap/models/models.html#gen_sequential_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#encodermap.models.models.gen_sequential_model" title="Permalink to this definition">#</a></dt>
<dd><p>Returns a tf.keras Model build with the specified input shape and the parameters in the Parameters class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_shape</strong> (<em>int</em>) – The input shape of the returned model. In most cases that is data.shape[1] of your data.</p></li>
<li><p><strong>parameters</strong> (<em>Union</em><em>[</em><a class="reference internal" href="../encodermap.html#encodermap.Parameters" title="encodermap.Parameters"><em>encodermap.Parameters</em></a><em>, </em><a class="reference internal" href="../encodermap.html#encodermap.ADCParameters" title="encodermap.ADCParameters"><em>encodermap.ADCParameters</em></a><em>, </em><em>None</em><em>]</em><em>, </em><em>optional</em>) – The parameters to
use on the returned model. If None is provided the default parameters in encodermap.Parameters.defaults
is used. You can look at the defaults with print(em.Parameters.defaults_description()). Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A subclass of tf.keras.Model build with specified parameters.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>em.SequentialModel</p>
</dd>
</dl>
</dd></dl>

<div class="toctree-wrapper compound">
</div>
</section>


            </article>
            
            
            
            <footer class="bd-footer-article">
                <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="featurization.html" title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">Featurization</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="layers.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">Layers</p>
  </div>
  <i class="fa-solid fa-angle-right"></i>
  </a>
</div>
            </footer>
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodermap.models.models.ADCSequentialModel">
   <code class="docutils literal notranslate">
    <span class="pre">
     ADCSequentialModel
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.ADCSequentialModel.call">
     <code class="docutils literal notranslate">
      <span class="pre">
       ADCSequentialModel.call()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.ADCSequentialModel.call_and_map_back">
     <code class="docutils literal notranslate">
      <span class="pre">
       ADCSequentialModel.call_and_map_back()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.ADCSequentialModel.train_step">
     <code class="docutils literal notranslate">
      <span class="pre">
       ADCSequentialModel.train_step()
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodermap.models.models.FunctionalModel">
   <code class="docutils literal notranslate">
    <span class="pre">
     FunctionalModel
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.FunctionalModel.compile">
     <code class="docutils literal notranslate">
      <span class="pre">
       FunctionalModel.compile()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.FunctionalModel.decoder">
     <code class="docutils literal notranslate">
      <span class="pre">
       FunctionalModel.decoder()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.FunctionalModel.encoder">
     <code class="docutils literal notranslate">
      <span class="pre">
       FunctionalModel.encoder()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.FunctionalModel.get_loss">
     <code class="docutils literal notranslate">
      <span class="pre">
       FunctionalModel.get_loss()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.FunctionalModel.train_step">
     <code class="docutils literal notranslate">
      <span class="pre">
       FunctionalModel.train_step()
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodermap.models.models.SequentialModel">
   <code class="docutils literal notranslate">
    <span class="pre">
     SequentialModel
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.SequentialModel.build">
     <code class="docutils literal notranslate">
      <span class="pre">
       SequentialModel.build()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.SequentialModel.call">
     <code class="docutils literal notranslate">
      <span class="pre">
       SequentialModel.call()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.SequentialModel.compile">
     <code class="docutils literal notranslate">
      <span class="pre">
       SequentialModel.compile()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.SequentialModel.decoder">
     <code class="docutils literal notranslate">
      <span class="pre">
       SequentialModel.decoder()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.SequentialModel.encoder">
     <code class="docutils literal notranslate">
      <span class="pre">
       SequentialModel.encoder()
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.SequentialModel.train_step">
     <code class="docutils literal notranslate">
      <span class="pre">
       SequentialModel.train_step()
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodermap.models.models.Sparse">
   <code class="docutils literal notranslate">
    <span class="pre">
     Sparse
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.Sparse.call">
     <code class="docutils literal notranslate">
      <span class="pre">
       Sparse.call()
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodermap.models.models.SparseFunctionalModel">
   <code class="docutils literal notranslate">
    <span class="pre">
     SparseFunctionalModel
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.SparseFunctionalModel.get_loss">
     <code class="docutils literal notranslate">
      <span class="pre">
       SparseFunctionalModel.get_loss()
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodermap.models.models.SparseModel">
   <code class="docutils literal notranslate">
    <span class="pre">
     SparseModel
    </span>
   </code>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#encodermap.models.models.SparseModel.call">
     <code class="docutils literal notranslate">
      <span class="pre">
       SparseModel.call()
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodermap.models.models.gen_functional_model">
   <code class="docutils literal notranslate">
    <span class="pre">
     gen_functional_model()
    </span>
   </code>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encodermap.models.models.gen_sequential_model">
   <code class="docutils literal notranslate">
    <span class="pre">
     gen_sequential_model()
    </span>
   </code>
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
<div class="tocsection sourcelink">
    <a href="../_sources/reference/models.rst.txt">
        <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
</div>

</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=796348d33e8b1d947c94"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=796348d33e8b1d947c94"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2023, Kevin Sawade, Tobias Lemke.<br>

</p>

  </div>
  
  <div class="footer-item">
    <p class="theme-version">
    Built with the
    <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">
        PyData Sphinx Theme
    </a>
    0.12.0.
</p>
  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.3.0.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>