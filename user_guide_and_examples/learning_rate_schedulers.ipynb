{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6761ef",
   "metadata": {},
   "source": [
    "# Learning Rate Scheduler\n",
    "\n",
    "Run this notebook on Google Colab:\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AG-Peter/encodermap/blob/main/tutorials/notebooks_customization/learning_rate_schedulers.ipynb)\n",
    "\n",
    "Find the documentation of EncoderMap:\n",
    "\n",
    "https://ag-peter.github.io/encodermap\n",
    "\n",
    "### For Google colab only:\n",
    "\n",
    "If you're on Google colab, please uncomment these lines and install EncoderMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408f06e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:39.341460Z",
     "iopub.status.busy": "2023-02-02T13:00:39.341112Z",
     "iopub.status.idle": "2023-02-02T13:00:39.344657Z",
     "shell.execute_reply": "2023-02-02T13:00:39.344050Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/install_encodermap_google_colab.sh\n",
    "# !sudo bash install_encodermap_google_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b78d1",
   "metadata": {},
   "source": [
    "If you're on Google Colab, you also want to download the data we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16654191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:39.347446Z",
     "iopub.status.busy": "2023-02-02T13:00:39.346922Z",
     "iopub.status.idle": "2023-02-02T13:00:39.349758Z",
     "shell.execute_reply": "2023-02-02T13:00:39.349310Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/notebooks_starter/asp7.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43decefb",
   "metadata": {},
   "source": [
    "## Primer\n",
    "\n",
    "In this tutorial you will learn how to use the `LearningRateScheduler` to dynamically alter the learning rate of your encodermap trainings. As usual we will begin by importing some modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6be3e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:39.352598Z",
     "iopub.status.busy": "2023-02-02T13:00:39.352072Z",
     "iopub.status.idle": "2023-02-02T13:00:42.537169Z",
     "shell.execute_reply": "2023-02-02T13:00:42.536511Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 13:00:39.499289: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 13:00:39.629291: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-02 13:00:39.629313: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 13:00:40.281864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-02 13:00:40.281946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-02 13:00:40.281954: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0546d1b762140d2b40c0a45af2e66e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import encodermap as em\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05def998",
   "metadata": {},
   "source": [
    "We wil work in the directory `runs/lr_scheduler`. So we will create it and then worry about tensorflow later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cb6a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:42.541082Z",
     "iopub.status.busy": "2023-02-02T13:00:42.540529Z",
     "iopub.status.idle": "2023-02-02T13:00:42.544486Z",
     "shell.execute_reply": "2023-02-02T13:00:42.543910Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('runs/lr_scheduler', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1063547",
   "metadata": {},
   "source": [
    "## Log the current learning rate to Tensorboard\n",
    "\n",
    "Before we implement some dynamic learning rates we want to find a way to log the learning rate to tensorboard. We will log the training to `runs/lr_scheduler` so navigate to this directory with\n",
    "\n",
    "```bash\n",
    "$ cd runs/lr_scheduler\n",
    "```\n",
    "\n",
    "and start tensorboard.\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir . --reload_multifile True\n",
    "```\n",
    "You should now be able to open TensorBoard in your webbrowser on port 6006.\n",
    "0.0.0.0:6006 or 127.0.0.1:6006\n",
    "\n",
    "If you're on Google colab, you can start tensorboard by uncommenting the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5bcabb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:42.547174Z",
     "iopub.status.busy": "2023-02-02T13:00:42.546833Z",
     "iopub.status.idle": "2023-02-02T13:00:42.549682Z",
     "shell.execute_reply": "2023-02-02T13:00:42.549059Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c9b43",
   "metadata": {},
   "source": [
    "To write our current learning rate to tensorboard we will use `EncoderMap`'s `EncoderMapBaseCallback` and create a subclass of it.\n",
    "\n",
    "We don't even need to define an `__init__()` method, as we can just use the parent's class `__init__()` method. We only need to overwrite either the `on_summary_step(self, batch, logs={})` or the `on_checkpoint_step(self, batch, logs={})` class methods. This depends, whether you want to execute the method every `summary_step` steps or every `checkpoint_steps`. The difference between the two can be taken from `EncoderMap`'s `Parameter` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b96f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:42.552137Z",
     "iopub.status.busy": "2023-02-02T13:00:42.551925Z",
     "iopub.status.idle": "2023-02-02T13:00:42.557086Z",
     "shell.execute_reply": "2023-02-02T13:00:42.556457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Parameter            | Default Value            | Description                                         \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    n_neurons            | [128, 128, 2]            | List containing number of neurons for each layer    \n",
      "                         |                          | up to the bottleneck layer. For example [128, 128,  \n",
      "                         |                          | 2] stands for an autoencoder with the following     \n",
      "                         |                          | architecture {i, 128, 128, 2, 128, 128, i} where i  \n",
      "                         |                          | is the number of dimensions of the input data.      \n",
      "                         |                          | These are Input/Output Layers that are not          \n",
      "                         |                          | trained.                                            \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    activation_functions | ['', 'tanh', 'tanh', ''] | List of activation function names as implemented    \n",
      "                         |                          | in TensorFlow. For example: \"relu\", \"tanh\",         \n",
      "                         |                          | \"sigmoid\" or \"\" to use no activation function. The  \n",
      "                         |                          | encoder part of the network takes the activation    \n",
      "                         |                          | functions from the list starting with the second    \n",
      "                         |                          | element. The decoder part of the network takes the  \n",
      "                         |                          | activation functions in reversed order starting     \n",
      "                         |                          | with the second element form the back. For example  \n",
      "                         |                          | [\"\", \"relu\", \"tanh\", \"\"] would result in a          \n",
      "                         |                          | autoencoder with {\"relu\", \"tanh\", \"\", \"tanh\",       \n",
      "                         |                          | \"relu\", \"\"} as sequence of activation functions.    \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    periodicity          | 6.283185307179586        | Defines the distance between periodic walls for     \n",
      "                         |                          | the inputs. For example 2pi for angular values in   \n",
      "                         |                          | radians. All periodic data processed by EncoderMap  \n",
      "                         |                          | must be wrapped to one periodic window. E.g. data   \n",
      "                         |                          | with 2pi periodicity may contain values from -pi    \n",
      "                         |                          | to pi or from 0 to 2pi. Set the periodicity to      \n",
      "                         |                          | float(\"inf\") for non-periodic inputs.               \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    learning_rate        | 0.001                    | Learning rate used by the optimizer.                \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    n_steps              | 100000                   | Number of training steps.                           \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    batch_size           | 256                      | Number of training points used in each training     \n",
      "                         |                          | step                                                \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    summary_step         | 10                       | A summary for TensorBoard is writen every           \n",
      "                         |                          | summary_step steps.                                 \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    checkpoint_step      | 5000                     | A checkpoint is writen every checkpoint_step        \n",
      "                         |                          | steps.                                              \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    dist_sig_parameters  | (4.5, 12, 6, 1, 2, 6)    | Parameters for the sigmoid functions applied to     \n",
      "                         |                          | the high- and low-dimensional distances in the      \n",
      "                         |                          | following order (sig_h, a_h, b_h, sig_l, a_l, b_l)  \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    distance_cost_scale  | 500                      | Adjusts how much the distance based metric is       \n",
      "                         |                          | weighted in the cost function.                      \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    auto_cost_scale      | 1                        | Adjusts how much the autoencoding cost is weighted  \n",
      "                         |                          | in the cost function.                               \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    auto_cost_variant    | mean_abs                 | defines how the auto cost is calculated. Must be    \n",
      "                         |                          | one of: * `mean_square` * `mean_abs` * `mean_norm`  \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    center_cost_scale    | 0.0001                   | Adjusts how much the centering cost is weighted in  \n",
      "                         |                          | the cost function.                                  \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    l2_reg_constant      | 0.001                    | Adjusts how much the L2 regularisation is weighted  \n",
      "                         |                          | in the cost function.                               \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    gpu_memory_fraction  |                          | Specifies the fraction of gpu memory blocked. If    \n",
      "                         |                          | set to 0, memory is allocated as needed.            \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    analysis_path        |                          | A path that can be used to store analysis           \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    id                   |                          | Can be any name for the run. Might be useful for    \n",
      "                         |                          | example for specific analysis for different data    \n",
      "                         |                          | sets.                                               \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    model_api            | sequential               | A string defining the API to be used to build the   \n",
      "                         |                          | keras model. Defaults to `sequntial`. Possible      \n",
      "                         |                          | strings are: * `functional` will use keras'         \n",
      "                         |                          | functional API. * `sequential` will define a keras  \n",
      "                         |                          | Model, containing two other models with the         \n",
      "                         |                          | Sequential API. These two models are encoder and    \n",
      "                         |                          | decoder. * `custom` will create a custom Model      \n",
      "                         |                          | where even the layers are custom.                   \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    loss                 | emap_cost                | A string defining the loss function. Defaults to    \n",
      "                         |                          | `emap_cost`. Possible losses are: *                 \n",
      "                         |                          | `reconstruction_loss` will try to train output ==   \n",
      "                         |                          | input * `mse`: Returns a mean squared error loss.   \n",
      "                         |                          | * `emap_cost` is the EncoderMap loss function.      \n",
      "                         |                          | Depending on the class `Autoencoder`, `Encodermap,  \n",
      "                         |                          | `ACDAutoencoder`, different contributions are used  \n",
      "                         |                          | for a combined loss. Autoencoder uses atuo_cost,    \n",
      "                         |                          | reg_cost, center_cost. EncoderMap class adds        \n",
      "                         |                          | sigmoid_loss.                                       \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    training             | auto                     | A string defining what kind of training is          \n",
      "                         |                          | performed when autoencoder.train() is callsed. *    \n",
      "                         |                          | `auto` does a regular model.compile() and           \n",
      "                         |                          | model.fit() procedure. * `custom` uses gradient     \n",
      "                         |                          | tape and calculates losses and gradients manually.  \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    batched              | True                     | Whether the dataset is batched or not.              \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    tensorboard          |                          | Whether to print tensorboard information. Defaults  \n",
      "                         |                          | to False.                                           \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    seed                 |                          | Fixes the state of all operations using random    \n"
     ]
    }
   ],
   "source": [
    "print(em.Parameters.defaults_description())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1be9cf",
   "metadata": {},
   "source": [
    "Here's the Logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c34f6e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:42.560724Z",
     "iopub.status.busy": "2023-02-02T13:00:42.560515Z",
     "iopub.status.idle": "2023-02-02T13:00:42.564235Z",
     "shell.execute_reply": "2023-02-02T13:00:42.563610Z"
    }
   },
   "outputs": [],
   "source": [
    "class LearningRateLogger(em.EncoderMapBaseCallback):\n",
    "    def on_summary_step(self, step, logs=None):\n",
    "        with tf.name_scope(\"Learning Rate\"):\n",
    "            tf.summary.scalar('current learning rate', self.model.optimizer.lr, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f53d462",
   "metadata": {},
   "source": [
    "We can now create an `EncoderMap` class and add our new callback. Note, how we instantiate our subclass by providing an instance of the `Parameters` class. That's how the callback knows what `summary_step` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf99bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:42.566686Z",
     "iopub.status.busy": "2023-02-02T13:00:42.566474Z",
     "iopub.status.idle": "2023-02-02T13:00:42.754139Z",
     "shell.execute_reply": "2023-02-02T13:00:42.752420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files are saved to runs/lr_scheduler/run0 as defined in 'main_path' in the parameters.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved a text-summary of the model and an image in runs/lr_scheduler/run0, as specified in 'main_path' in the parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 13:00:42.589334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-02 13:00:42.589360: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-02 13:00:42.589378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fv-az442-794): /proc/driver/nvidia/version does not exist\n",
      "2023-02-02 13:00:42.589569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('asp7.csv')\n",
    "dihedrals = df.iloc[:,:-1].values.astype(np.float32)\n",
    "cluster_ids = df.iloc[:,-1].values\n",
    "\n",
    "parameters = em.Parameters(\n",
    "tensorboard=True,\n",
    "periodicity=2*np.pi,\n",
    "main_path=em.misc.run_path('runs/lr_scheduler'),\n",
    "n_steps=100,\n",
    "summary_step=5\n",
    ")\n",
    "\n",
    "# create an instance of EncoderMap\n",
    "e_map = em.EncoderMap(parameters, dihedrals)\n",
    "\n",
    "# Add an instance of the new Callback\n",
    "e_map.callbacks.append(LearningRateLogger(parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214e7f1",
   "metadata": {},
   "source": [
    "**train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96569684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:42.757122Z",
     "iopub.status.busy": "2023-02-02T13:00:42.756728Z",
     "iopub.status.idle": "2023-02-02T13:00:52.046504Z",
     "shell.execute_reply": "2023-02-02T13:00:52.045855Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:05<09:29,  5.76s/it, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:05<09:12,  5.76s/it, Loss after step 5=81.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:05<00:57,  1.62it/s, Loss after step 5=81.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:05<00:56,  1.62it/s, Loss after step 10=42.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [00:05<00:24,  3.57it/s, Loss after step 10=42.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [00:05<00:24,  3.57it/s, Loss after step 15=40.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [00:06<00:13,  6.12it/s, Loss after step 15=40.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [00:06<00:13,  6.12it/s, Loss after step 20=40.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [00:06<00:12,  6.12it/s, Loss after step 25=45.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [00:06<00:07,  9.38it/s, Loss after step 25=45.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [00:06<00:07,  9.38it/s, Loss after step 30=44.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 32/100 [00:06<00:04, 14.04it/s, Loss after step 30=44.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [00:06<00:04, 14.04it/s, Loss after step 35=40.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 38/100 [00:06<00:03, 18.57it/s, Loss after step 35=40.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [00:06<00:03, 18.57it/s, Loss after step 40=42]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [00:06<00:02, 23.64it/s, Loss after step 40=42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [00:06<00:02, 23.64it/s, Loss after step 45=40.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [00:06<00:02, 23.64it/s, Loss after step 50=41.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 50/100 [00:06<00:01, 28.89it/s, Loss after step 50=41.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [00:06<00:01, 28.89it/s, Loss after step 55=40.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [00:06<00:01, 33.81it/s, Loss after step 55=40.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [00:06<00:01, 33.81it/s, Loss after step 60=38.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 62/100 [00:06<00:00, 38.75it/s, Loss after step 60=38.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [00:06<00:00, 38.75it/s, Loss after step 65=40.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 68/100 [00:06<00:00, 42.96it/s, Loss after step 65=40.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [00:06<00:00, 42.96it/s, Loss after step 70=37.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [00:07<00:00, 46.45it/s, Loss after step 70=37.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [00:07<00:00, 46.45it/s, Loss after step 75=38.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [00:07<00:00, 46.45it/s, Loss after step 80=37.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [00:07<00:00, 49.67it/s, Loss after step 80=37.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [00:07<00:00, 49.67it/s, Loss after step 85=36.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [00:07<00:00, 51.33it/s, Loss after step 85=36.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [00:07<00:00, 51.33it/s, Loss after step 90=36.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 92/100 [00:07<00:00, 53.16it/s, Loss after step 90=36.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [00:07<00:00, 53.16it/s, Loss after step 95=40.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 98/100 [00:07<00:00, 52.89it/s, Loss after step 95=40.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [00:07<00:00, 52.89it/s, Loss after step 100=38.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 100/100 [00:07<00:00, 13.34it/s, Loss after step 100=38.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Encoder_0_input with unsupported characters which will be renamed to encoder_0_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Decoder_0_input with unsupported characters which will be renamed to decoder_0_input in the SavedModel.\n"
     ]
    }
   ],
   "source": [
    "e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5688138",
   "metadata": {},
   "source": [
    "Here's what Tensorboard should look like:\n",
    "\n",
    "<img src=\"lr_scheduler_1.png\" width=\"800\">\n",
    "\n",
    "A constant learning rate of 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598068c0",
   "metadata": {},
   "source": [
    "## Write a learning rate scheduler.\n",
    "\n",
    "We can write a learning rate scheduler either by providing intervals of training steps and the associated learning rate:\n",
    "\n",
    "```python\n",
    "def lr_schedule(step):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as steps progress.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.2\n",
    "    if step > 10:\n",
    "        learning_rate = 0.02\n",
    "    if step > 20:\n",
    "        learning_rate = 0.01\n",
    "    if step > 50:\n",
    "        learning_rate = 0.005\n",
    "```\n",
    "\n",
    "Or by using a function that gives us a learning rate:\n",
    "\n",
    "```python\n",
    "def scheduler(step, lr=1, n_steps=1000):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases based on an exp function as steps progress.\n",
    "    \"\"\"\n",
    "    if step < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-step / n_steps)\n",
    "```\n",
    "\n",
    "Below, is an example combining both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a37f62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:52.049809Z",
     "iopub.status.busy": "2023-02-02T13:00:52.049376Z",
     "iopub.status.idle": "2023-02-02T13:00:52.054229Z",
     "shell.execute_reply": "2023-02-02T13:00:52.053636Z"
    }
   },
   "outputs": [],
   "source": [
    "def scheduler(step, lr=1):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases based on an exp function as steps progress.\n",
    "    \"\"\"\n",
    "    if step < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848aa1d",
   "metadata": {},
   "source": [
    "This scheduler function can simply be provided to the builtin `keras.callbacks.LearningRateScheduler` callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "332faaec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:52.056918Z",
     "iopub.status.busy": "2023-02-02T13:00:52.056585Z",
     "iopub.status.idle": "2023-02-02T13:00:52.060820Z",
     "shell.execute_reply": "2023-02-02T13:00:52.060181Z"
    }
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f22dc5",
   "metadata": {},
   "source": [
    "And appended to the list of `callbacks` in the EncoderMap class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9087259e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:52.063366Z",
     "iopub.status.busy": "2023-02-02T13:00:52.063032Z",
     "iopub.status.idle": "2023-02-02T13:00:52.224124Z",
     "shell.execute_reply": "2023-02-02T13:00:52.223399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files are saved to runs/lr_scheduler/run1 as defined in 'main_path' in the parameters.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved a text-summary of the model and an image in runs/lr_scheduler/run1, as specified in 'main_path' in the parameters.\n"
     ]
    }
   ],
   "source": [
    "parameters = em.Parameters(\n",
    "tensorboard=True,\n",
    "periodicity=2*np.pi,\n",
    "main_path=em.misc.run_path('runs/lr_scheduler'),\n",
    "n_steps=50,\n",
    "summary_step=5\n",
    ")\n",
    "\n",
    "e_map = em.EncoderMap(parameters, dihedrals)\n",
    "e_map.callbacks.append(LearningRateLogger(parameters))\n",
    "e_map.callbacks.append(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b026be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-02T13:00:52.227236Z",
     "iopub.status.busy": "2023-02-02T13:00:52.226991Z",
     "iopub.status.idle": "2023-02-02T13:00:59.969923Z",
     "shell.execute_reply": "2023-02-02T13:00:59.969160Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [00:05<04:33,  5.58s/it, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [00:05<04:16,  5.58s/it, Loss after step 5=77.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [00:05<00:30,  1.42it/s, Loss after step 5=77.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:05<00:28,  1.42it/s, Loss after step 10=47.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [00:05<00:11,  3.41it/s, Loss after step 10=47.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [00:05<00:10,  3.41it/s, Loss after step 15=40.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 17/50 [00:05<00:05,  5.58it/s, Loss after step 15=40.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [00:05<00:05,  5.58it/s, Loss after step 20=42.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 23/50 [00:06<00:03,  8.86it/s, Loss after step 20=42.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [00:06<00:02,  8.86it/s, Loss after step 25=41.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [00:06<00:01, 12.88it/s, Loss after step 25=41.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [00:06<00:01, 12.88it/s, Loss after step 30=39.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [00:06<00:01, 12.88it/s, Loss after step 35=43.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [00:06<00:00, 17.50it/s, Loss after step 35=43.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [00:06<00:00, 17.50it/s, Loss after step 40=42]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 41/50 [00:06<00:00, 22.54it/s, Loss after step 40=42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [00:06<00:00, 22.54it/s, Loss after step 45=39.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 47/50 [00:06<00:00, 27.60it/s, Loss after step 45=39.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [00:06<00:00, 27.60it/s, Loss after step 50=43.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:06<00:00,  7.66it/s, Loss after step 50=43.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Encoder_0_input with unsupported characters which will be renamed to encoder_0_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Decoder_0_input with unsupported characters which will be renamed to decoder_0_input in the SavedModel.\n"
     ]
    }
   ],
   "source": [
    "e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7973533f",
   "metadata": {},
   "source": [
    "Here's what Tensorboard should look like:\n",
    "\n",
    "<img src=\"lr_scheduler_2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc18f6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Learning rate schedulers are helpful to prevent overtraining, but still slightly increase the predictive power of your NN model. EncoderMap's modularity allows for them to be simple Plug-In solutions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "5f1e4b443c434b0b8b56b99d637b8f1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a0546d1b762140d2b40c0a45af2e66e0": {
      "model_module": "nglview-js-widgets",
      "model_module_version": "3.0.1",
      "model_name": "ColormakerRegistryModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "nglview-js-widgets",
       "_model_module_version": "3.0.1",
       "_model_name": "ColormakerRegistryModel",
       "_msg_ar": [],
       "_msg_q": [],
       "_ready": false,
       "_view_count": null,
       "_view_module": "nglview-js-widgets",
       "_view_module_version": "3.0.1",
       "_view_name": "ColormakerRegistryView",
       "layout": "IPY_MODEL_5f1e4b443c434b0b8b56b99d637b8f1e"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
