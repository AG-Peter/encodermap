{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6761ef",
   "metadata": {},
   "source": [
    "# Learning Rate Scheduler\n",
    "\n",
    "Run this notebook on Google Colab:\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AG-Peter/encodermap/blob/main/tutorials/notebooks_customization/learning_rate_schedulers.ipynb)\n",
    "\n",
    "Find the documentation of EncoderMap:\n",
    "\n",
    "https://ag-peter.github.io/encodermap\n",
    "\n",
    "### For Google colab only:\n",
    "\n",
    "If you're on Google colab, please uncomment these lines and install EncoderMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408f06e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:07.526664Z",
     "iopub.status.busy": "2023-02-07T11:10:07.526311Z",
     "iopub.status.idle": "2023-02-07T11:10:07.530764Z",
     "shell.execute_reply": "2023-02-07T11:10:07.529844Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/install_encodermap_google_colab.sh\n",
    "# !sudo bash install_encodermap_google_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b78d1",
   "metadata": {},
   "source": [
    "If you're on Google Colab, you also want to download the data we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16654191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:07.535078Z",
     "iopub.status.busy": "2023-02-07T11:10:07.534563Z",
     "iopub.status.idle": "2023-02-07T11:10:07.538222Z",
     "shell.execute_reply": "2023-02-07T11:10:07.537372Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/notebooks_starter/asp7.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43decefb",
   "metadata": {},
   "source": [
    "## Primer\n",
    "\n",
    "In this tutorial you will learn how to use the `LearningRateScheduler` to dynamically alter the learning rate of your encodermap trainings. As usual we will begin by importing some modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6be3e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:07.542093Z",
     "iopub.status.busy": "2023-02-07T11:10:07.541177Z",
     "iopub.status.idle": "2023-02-07T11:10:11.843389Z",
     "shell.execute_reply": "2023-02-07T11:10:11.842374Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:10:07.742660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-07 11:10:07.913266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-07 11:10:07.913290: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:10:08.765814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-07 11:10:08.765915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-07 11:10:08.765926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f63c4533a8e4939b19d2fade4b38fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import encodermap as em\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05def998",
   "metadata": {},
   "source": [
    "We wil work in the directory `runs/lr_scheduler`. So we will create it and then worry about tensorflow later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cb6a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:11.847555Z",
     "iopub.status.busy": "2023-02-07T11:10:11.846993Z",
     "iopub.status.idle": "2023-02-07T11:10:11.852550Z",
     "shell.execute_reply": "2023-02-07T11:10:11.851795Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('runs/lr_scheduler', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1063547",
   "metadata": {},
   "source": [
    "## Log the current learning rate to Tensorboard\n",
    "\n",
    "Before we implement some dynamic learning rates we want to find a way to log the learning rate to tensorboard. We will log the training to `runs/lr_scheduler` so navigate to this directory with\n",
    "\n",
    "```bash\n",
    "$ cd runs/lr_scheduler\n",
    "```\n",
    "\n",
    "and start tensorboard.\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir . --reload_multifile True\n",
    "```\n",
    "You should now be able to open TensorBoard in your webbrowser on port 6006.\n",
    "0.0.0.0:6006 or 127.0.0.1:6006\n",
    "\n",
    "If you're on Google colab, you can start tensorboard by uncommenting the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5bcabb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:11.856925Z",
     "iopub.status.busy": "2023-02-07T11:10:11.856398Z",
     "iopub.status.idle": "2023-02-07T11:10:11.859845Z",
     "shell.execute_reply": "2023-02-07T11:10:11.859056Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c9b43",
   "metadata": {},
   "source": [
    "To write our current learning rate to tensorboard we will use `EncoderMap`'s `EncoderMapBaseCallback` and create a subclass of it.\n",
    "\n",
    "We don't even need to define an `__init__()` method, as we can just use the parent's class `__init__()` method. We only need to overwrite either the `on_summary_step(self, batch, logs={})` or the `on_checkpoint_step(self, batch, logs={})` class methods. This depends, whether you want to execute the method every `summary_step` steps or every `checkpoint_steps`. The difference between the two can be taken from `EncoderMap`'s `Parameter` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b96f2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:11.863955Z",
     "iopub.status.busy": "2023-02-07T11:10:11.863001Z",
     "iopub.status.idle": "2023-02-07T11:10:11.869635Z",
     "shell.execute_reply": "2023-02-07T11:10:11.869004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Parameter            | Default Value            | Description                                         \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    n_neurons            | [128, 128, 2]            | List containing number of neurons for each layer    \n",
      "                         |                          | up to the bottleneck layer. For example [128, 128,  \n",
      "                         |                          | 2] stands for an autoencoder with the following     \n",
      "                         |                          | architecture {i, 128, 128, 2, 128, 128, i} where i  \n",
      "                         |                          | is the number of dimensions of the input data.      \n",
      "                         |                          | These are Input/Output Layers that are not          \n",
      "                         |                          | trained.                                            \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    activation_functions | ['', 'tanh', 'tanh', ''] | List of activation function names as implemented    \n",
      "                         |                          | in TensorFlow. For example: \"relu\", \"tanh\",         \n",
      "                         |                          | \"sigmoid\" or \"\" to use no activation function. The  \n",
      "                         |                          | encoder part of the network takes the activation    \n",
      "                         |                          | functions from the list starting with the second    \n",
      "                         |                          | element. The decoder part of the network takes the  \n",
      "                         |                          | activation functions in reversed order starting     \n",
      "                         |                          | with the second element form the back. For example  \n",
      "                         |                          | [\"\", \"relu\", \"tanh\", \"\"] would result in a          \n",
      "                         |                          | autoencoder with {\"relu\", \"tanh\", \"\", \"tanh\",       \n",
      "                         |                          | \"relu\", \"\"} as sequence of activation functions.    \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    periodicity          | 6.283185307179586        | Defines the distance between periodic walls for     \n",
      "                         |                          | the inputs. For example 2pi for angular values in   \n",
      "                         |                          | radians. All periodic data processed by EncoderMap  \n",
      "                         |                          | must be wrapped to one periodic window. E.g. data   \n",
      "                         |                          | with 2pi periodicity may contain values from -pi    \n",
      "                         |                          | to pi or from 0 to 2pi. Set the periodicity to      \n",
      "                         |                          | float(\"inf\") for non-periodic inputs.               \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    learning_rate        | 0.001                    | Learning rate used by the optimizer.                \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    n_steps              | 100000                   | Number of training steps.                           \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    batch_size           | 256                      | Number of training points used in each training     \n",
      "                         |                          | step                                                \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    summary_step         | 10                       | A summary for TensorBoard is writen every           \n",
      "                         |                          | summary_step steps.                                 \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    checkpoint_step      | 5000                     | A checkpoint is writen every checkpoint_step        \n",
      "                         |                          | steps.                                              \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    dist_sig_parameters  | (4.5, 12, 6, 1, 2, 6)    | Parameters for the sigmoid functions applied to     \n",
      "                         |                          | the high- and low-dimensional distances in the      \n",
      "                         |                          | following order (sig_h, a_h, b_h, sig_l, a_l, b_l)  \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    distance_cost_scale  | 500                      | Adjusts how much the distance based metric is       \n",
      "                         |                          | weighted in the cost function.                      \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    auto_cost_scale      | 1                        | Adjusts how much the autoencoding cost is weighted  \n",
      "                         |                          | in the cost function.                               \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    auto_cost_variant    | mean_abs                 | defines how the auto cost is calculated. Must be    \n",
      "                         |                          | one of: * `mean_square` * `mean_abs` * `mean_norm`  \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    center_cost_scale    | 0.0001                   | Adjusts how much the centering cost is weighted in  \n",
      "                         |                          | the cost function.                                  \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    l2_reg_constant      | 0.001                    | Adjusts how much the L2 regularisation is weighted  \n",
      "                         |                          | in the cost function.                               \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    gpu_memory_fraction  |                          | Specifies the fraction of gpu memory blocked. If    \n",
      "                         |                          | set to 0, memory is allocated as needed.            \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    analysis_path        |                          | A path that can be used to store analysis           \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    id                   |                          | Can be any name for the run. Might be useful for    \n",
      "                         |                          | example for specific analysis for different data    \n",
      "                         |                          | sets.                                               \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    model_api            | sequential               | A string defining the API to be used to build the   \n",
      "                         |                          | keras model. Defaults to `sequntial`. Possible      \n",
      "                         |                          | strings are: * `functional` will use keras'         \n",
      "                         |                          | functional API. * `sequential` will define a keras  \n",
      "                         |                          | Model, containing two other models with the         \n",
      "                         |                          | Sequential API. These two models are encoder and    \n",
      "                         |                          | decoder. * `custom` will create a custom Model      \n",
      "                         |                          | where even the layers are custom.                   \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    loss                 | emap_cost                | A string defining the loss function. Defaults to    \n",
      "                         |                          | `emap_cost`. Possible losses are: *                 \n",
      "                         |                          | `reconstruction_loss` will try to train output ==   \n",
      "                         |                          | input * `mse`: Returns a mean squared error loss.   \n",
      "                         |                          | * `emap_cost` is the EncoderMap loss function.      \n",
      "                         |                          | Depending on the class `Autoencoder`, `Encodermap,  \n",
      "                         |                          | `ACDAutoencoder`, different contributions are used  \n",
      "                         |                          | for a combined loss. Autoencoder uses atuo_cost,    \n",
      "                         |                          | reg_cost, center_cost. EncoderMap class adds        \n",
      "                         |                          | sigmoid_loss.                                       \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    training             | auto                     | A string defining what kind of training is          \n",
      "                         |                          | performed when autoencoder.train() is callsed. *    \n",
      "                         |                          | `auto` does a regular model.compile() and           \n",
      "                         |                          | model.fit() procedure. * `custom` uses gradient     \n",
      "                         |                          | tape and calculates losses and gradients manually.  \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    batched              | True                     | Whether the dataset is batched or not.              \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    tensorboard          |                          | Whether to print tensorboard information. Defaults  \n",
      "                         |                          | to False.                                           \n",
      "    ---------------------+--------------------------+---------------------------------------------------  \n",
      "    seed                 |                          | Fixes the state of all operations using random    \n"
     ]
    }
   ],
   "source": [
    "print(em.Parameters.defaults_description())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1be9cf",
   "metadata": {},
   "source": [
    "Here's the Logger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c34f6e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:11.873441Z",
     "iopub.status.busy": "2023-02-07T11:10:11.873164Z",
     "iopub.status.idle": "2023-02-07T11:10:11.878185Z",
     "shell.execute_reply": "2023-02-07T11:10:11.877401Z"
    }
   },
   "outputs": [],
   "source": [
    "class LearningRateLogger(em.EncoderMapBaseCallback):\n",
    "    def on_summary_step(self, step, logs=None):\n",
    "        with tf.name_scope(\"Learning Rate\"):\n",
    "            tf.summary.scalar('current learning rate', self.model.optimizer.lr, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f53d462",
   "metadata": {},
   "source": [
    "We can now create an `EncoderMap` class and add our new callback. Note, how we instantiate our subclass by providing an instance of the `Parameters` class. That's how the callback knows what `summary_step` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf99bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:11.881795Z",
     "iopub.status.busy": "2023-02-07T11:10:11.881176Z",
     "iopub.status.idle": "2023-02-07T11:10:12.131747Z",
     "shell.execute_reply": "2023-02-07T11:10:12.130928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files are saved to runs/lr_scheduler/run0 as defined in 'main_path' in the parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:10:11.912906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-07 11:10:11.912943: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-07 11:10:11.912966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fv-az267-630): /proc/driver/nvidia/version does not exist\n",
      "2023-02-07 11:10:11.913215: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved a text-summary of the model and an image in runs/lr_scheduler/run0, as specified in 'main_path' in the parameters.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('asp7.csv')\n",
    "dihedrals = df.iloc[:,:-1].values.astype(np.float32)\n",
    "cluster_ids = df.iloc[:,-1].values\n",
    "\n",
    "parameters = em.Parameters(\n",
    "tensorboard=True,\n",
    "periodicity=2*np.pi,\n",
    "main_path=em.misc.run_path('runs/lr_scheduler'),\n",
    "n_steps=100,\n",
    "summary_step=5\n",
    ")\n",
    "\n",
    "# create an instance of EncoderMap\n",
    "e_map = em.EncoderMap(parameters, dihedrals)\n",
    "\n",
    "# Add an instance of the new Callback\n",
    "e_map.callbacks.append(LearningRateLogger(parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214e7f1",
   "metadata": {},
   "source": [
    "**train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96569684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:12.135857Z",
     "iopub.status.busy": "2023-02-07T11:10:12.135303Z",
     "iopub.status.idle": "2023-02-07T11:10:23.925463Z",
     "shell.execute_reply": "2023-02-07T11:10:23.924598Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:08<13:13,  8.01s/it, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:08<12:49,  8.01s/it, Loss after step 5=85.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:08<01:34,  1.01s/it, Loss after step 5=85.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:08<01:31,  1.01s/it, Loss after step 10=50.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [00:08<00:40,  2.18it/s, Loss after step 10=50.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [00:08<00:39,  2.18it/s, Loss after step 15=45.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [00:08<00:22,  3.77it/s, Loss after step 15=45.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [00:08<00:21,  3.77it/s, Loss after step 20=49.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [00:08<00:13,  5.84it/s, Loss after step 20=49.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 24/100 [00:08<00:13,  5.84it/s, Loss after step 25=46.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [00:08<00:08,  8.44it/s, Loss after step 25=46.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [00:08<00:08,  8.44it/s, Loss after step 30=42]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [00:08<00:05, 11.61it/s, Loss after step 30=42]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 34/100 [00:08<00:05, 11.61it/s, Loss after step 35=42.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [00:08<00:04, 15.29it/s, Loss after step 35=42.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [00:08<00:03, 15.29it/s, Loss after step 40=47.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [00:08<00:03, 19.37it/s, Loss after step 40=47.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 44/100 [00:09<00:02, 19.37it/s, Loss after step 45=43.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [00:09<00:02, 23.85it/s, Loss after step 45=43.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [00:09<00:02, 23.85it/s, Loss after step 50=41.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [00:09<00:01, 27.73it/s, Loss after step 50=41.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 54/100 [00:09<00:01, 27.73it/s, Loss after step 55=39.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [00:09<00:01, 31.79it/s, Loss after step 55=39.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [00:09<00:01, 31.79it/s, Loss after step 60=41.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [00:09<00:01, 35.30it/s, Loss after step 60=41.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 64/100 [00:09<00:01, 35.30it/s, Loss after step 65=37]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [00:09<00:00, 37.80it/s, Loss after step 65=37]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [00:09<00:00, 37.80it/s, Loss after step 70=37.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [00:09<00:00, 38.27it/s, Loss after step 70=37.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 74/100 [00:09<00:00, 38.27it/s, Loss after step 75=38]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [00:09<00:00, 39.43it/s, Loss after step 75=38]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [00:09<00:00, 39.43it/s, Loss after step 80=36.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [00:09<00:00, 41.28it/s, Loss after step 80=36.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 84/100 [00:09<00:00, 41.28it/s, Loss after step 85=39.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [00:09<00:00, 42.93it/s, Loss after step 85=39.2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [00:10<00:00, 42.93it/s, Loss after step 90=35.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [00:10<00:00, 43.45it/s, Loss after step 90=35.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 94/100 [00:10<00:00, 43.45it/s, Loss after step 95=34.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [00:10<00:00, 43.73it/s, Loss after step 95=34.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [00:10<00:00, 43.73it/s, Loss after step 100=34.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 100/100 [00:10<00:00,  9.78it/s, Loss after step 100=34.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Encoder_0_input with unsupported characters which will be renamed to encoder_0_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Decoder_0_input with unsupported characters which will be renamed to decoder_0_input in the SavedModel.\n"
     ]
    }
   ],
   "source": [
    "e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5688138",
   "metadata": {},
   "source": [
    "Here's what Tensorboard should look like:\n",
    "\n",
    "<img src=\"lr_scheduler_1.png\" width=\"800\">\n",
    "\n",
    "A constant learning rate of 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598068c0",
   "metadata": {},
   "source": [
    "## Write a learning rate scheduler.\n",
    "\n",
    "We can write a learning rate scheduler either by providing intervals of training steps and the associated learning rate:\n",
    "\n",
    "```python\n",
    "def lr_schedule(step):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases as steps progress.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.2\n",
    "    if step > 10:\n",
    "        learning_rate = 0.02\n",
    "    if step > 20:\n",
    "        learning_rate = 0.01\n",
    "    if step > 50:\n",
    "        learning_rate = 0.005\n",
    "```\n",
    "\n",
    "Or by using a function that gives us a learning rate:\n",
    "\n",
    "```python\n",
    "def scheduler(step, lr=1, n_steps=1000):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases based on an exp function as steps progress.\n",
    "    \"\"\"\n",
    "    if step < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-step / n_steps)\n",
    "```\n",
    "\n",
    "Below, is an example combining both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a37f62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:23.930911Z",
     "iopub.status.busy": "2023-02-07T11:10:23.930443Z",
     "iopub.status.idle": "2023-02-07T11:10:23.935057Z",
     "shell.execute_reply": "2023-02-07T11:10:23.934378Z"
    }
   },
   "outputs": [],
   "source": [
    "def scheduler(step, lr=1):\n",
    "    \"\"\"\n",
    "    Returns a custom learning rate that decreases based on an exp function as steps progress.\n",
    "    \"\"\"\n",
    "    if step < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848aa1d",
   "metadata": {},
   "source": [
    "This scheduler function can simply be provided to the builtin `keras.callbacks.LearningRateScheduler` callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "332faaec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:23.938815Z",
     "iopub.status.busy": "2023-02-07T11:10:23.938156Z",
     "iopub.status.idle": "2023-02-07T11:10:23.943453Z",
     "shell.execute_reply": "2023-02-07T11:10:23.942581Z"
    }
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f22dc5",
   "metadata": {},
   "source": [
    "And appended to the list of `callbacks` in the EncoderMap class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9087259e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:23.948164Z",
     "iopub.status.busy": "2023-02-07T11:10:23.947442Z",
     "iopub.status.idle": "2023-02-07T11:10:24.154867Z",
     "shell.execute_reply": "2023-02-07T11:10:24.154008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files are saved to runs/lr_scheduler/run1 as defined in 'main_path' in the parameters.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved a text-summary of the model and an image in runs/lr_scheduler/run1, as specified in 'main_path' in the parameters.\n"
     ]
    }
   ],
   "source": [
    "parameters = em.Parameters(\n",
    "tensorboard=True,\n",
    "periodicity=2*np.pi,\n",
    "main_path=em.misc.run_path('runs/lr_scheduler'),\n",
    "n_steps=50,\n",
    "summary_step=5\n",
    ")\n",
    "\n",
    "e_map = em.EncoderMap(parameters, dihedrals)\n",
    "e_map.callbacks.append(LearningRateLogger(parameters))\n",
    "e_map.callbacks.append(callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b026be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:10:24.158674Z",
     "iopub.status.busy": "2023-02-07T11:10:24.158107Z",
     "iopub.status.idle": "2023-02-07T11:10:34.008681Z",
     "shell.execute_reply": "2023-02-07T11:10:34.007721Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/50 [00:07<06:05,  7.45s/it, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 4/50 [00:07<05:42,  7.45s/it, Loss after step 5=70.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 6/50 [00:07<00:41,  1.07it/s, Loss after step 5=70.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [00:07<00:38,  1.07it/s, Loss after step 10=47.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 11/50 [00:07<00:16,  2.33it/s, Loss after step 10=47.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 14/50 [00:07<00:15,  2.33it/s, Loss after step 15=44.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 16/50 [00:07<00:08,  4.01it/s, Loss after step 15=44.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 19/50 [00:07<00:07,  4.01it/s, Loss after step 20=44.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 21/50 [00:07<00:04,  6.17it/s, Loss after step 20=44.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 24/50 [00:08<00:04,  6.17it/s, Loss after step 25=42.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 26/50 [00:08<00:02,  8.88it/s, Loss after step 25=42.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 29/50 [00:08<00:02,  8.88it/s, Loss after step 30=43.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 31/50 [00:08<00:01, 12.05it/s, Loss after step 30=43.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 34/50 [00:08<00:01, 12.05it/s, Loss after step 35=44.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 35/50 [00:08<00:01, 14.93it/s, Loss after step 35=44.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 39/50 [00:08<00:00, 14.93it/s, Loss after step 40=43]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 40/50 [00:08<00:00, 19.16it/s, Loss after step 40=43]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 44/50 [00:08<00:00, 19.16it/s, Loss after step 45=43.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 45/50 [00:08<00:00, 23.10it/s, Loss after step 45=43.6]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 49/50 [00:08<00:00, 23.10it/s, Loss after step 50=44.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:08<00:00, 26.99it/s, Loss after step 50=44.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 50/50 [00:08<00:00,  5.80it/s, Loss after step 50=44.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Encoder_0_input with unsupported characters which will be renamed to encoder_0_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Decoder_0_input with unsupported characters which will be renamed to decoder_0_input in the SavedModel.\n"
     ]
    }
   ],
   "source": [
    "e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7973533f",
   "metadata": {},
   "source": [
    "Here's what Tensorboard should look like:\n",
    "\n",
    "<img src=\"lr_scheduler_2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc18f6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Learning rate schedulers are helpful to prevent overtraining, but still slightly increase the predictive power of your NN model. EncoderMap's modularity allows for them to be simple Plug-In solutions."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0da646300e594e72bccb1eece573449a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0f63c4533a8e4939b19d2fade4b38fe0": {
      "model_module": "nglview-js-widgets",
      "model_module_version": "3.0.1",
      "model_name": "ColormakerRegistryModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "nglview-js-widgets",
       "_model_module_version": "3.0.1",
       "_model_name": "ColormakerRegistryModel",
       "_msg_ar": [],
       "_msg_q": [],
       "_ready": false,
       "_view_count": null,
       "_view_module": "nglview-js-widgets",
       "_view_module_version": "3.0.1",
       "_view_name": "ColormakerRegistryView",
       "layout": "IPY_MODEL_0da646300e594e72bccb1eece573449a"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
