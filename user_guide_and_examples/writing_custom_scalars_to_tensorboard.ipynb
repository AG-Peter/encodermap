{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68feb89b",
   "metadata": {},
   "source": [
    "# Logging Custom Scalars\n",
    "\n",
    "Run this notebook on Google Colab:\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AG-Peter/encodermap/blob/main/tutorials/notebooks_customization/writing_custom_scalars_to_tensorboard.ipynb)\n",
    "\n",
    "Find the documentation of EncoderMap:\n",
    "\n",
    "https://ag-peter.github.io/encodermap\n",
    "\n",
    "### For Google colab only:\n",
    "\n",
    "If you're on Google colab, please uncomment these lines and install EncoderMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f28dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:41.330758Z",
     "iopub.status.busy": "2023-02-07T11:14:41.330082Z",
     "iopub.status.idle": "2023-02-07T11:14:41.335170Z",
     "shell.execute_reply": "2023-02-07T11:14:41.334355Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/install_encodermap_google_colab.sh\n",
    "# !sudo bash install_encodermap_google_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1e4269",
   "metadata": {},
   "source": [
    "## Primer\n",
    "\n",
    "In this tutorial we will explore 2 different ways of logging custom scalars or custom data to tensorboard using EncoderMap and its codebase. First let us start with the required imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3913fd7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:41.338657Z",
     "iopub.status.busy": "2023-02-07T11:14:41.338154Z",
     "iopub.status.idle": "2023-02-07T11:14:45.388669Z",
     "shell.execute_reply": "2023-02-07T11:14:45.387606Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:14:41.533872: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-07 11:14:41.683195: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-07 11:14:41.683219: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:14:42.475242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-07 11:14:42.475326: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-07 11:14:42.475335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc51df8f0343454a8432f0c813aa6ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import encodermap as em\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99013363",
   "metadata": {},
   "source": [
    "## Subclassing a model and adding tf.summary\n",
    "\n",
    "**Idea:** Log different auto_cost_variants to tensorboard and see how they compare.\n",
    "\n",
    "EncoderMap's `auto_cost()` function compares the input and output of the autoencoder. The greater the difference the higher the returned loss. The next code fragment is taken from EncoderMap's code.\n",
    "\n",
    "```python\n",
    "def auto_cost_function(y_true, y_pred=None):\n",
    "    if y_pred is None:\n",
    "        y_pred = model(y_true)\n",
    "        \n",
    "    if p.auto_cost_scale is not None:\n",
    "        if p.auto_cost_variant == \"mean_square\":\n",
    "            auto_cost = tf.reduce_mean(\n",
    "                tf.square(periodic_distance(y_true, y_pred, p.periodicity)))\n",
    "        elif p.auto_cost_variant == \"mean_abs\":\n",
    "            auto_cost = tf.reduce_mean(\n",
    "                tf.abs(periodic_distance(y_true, y_pred, p.periodicity)))\n",
    "        elif p.auto_cost_variant == \"mean_norm\":\n",
    "            auto_cost = tf.reduce_mean(\n",
    "                tf.norm(periodic_distance(y_true, y_pred, p.periodicity), axis=1))\n",
    "        else:\n",
    "            raise ValueError(\"auto_cost_variant {} not available\".format(p.auto_cost_variant))\n",
    "        if p.auto_cost_scale != 0:\n",
    "            auto_cost *= p.auto_cost_scale\n",
    "    else:\n",
    "        auto_cost = 0\n",
    "    tf.cond(write_bool, true_fn=lambda: _summary_cost('Auto Cost', auto_cost),\n",
    "            false_fn=lambda: _do_nothing(), name=\"Cost\")\n",
    "```\n",
    "\n",
    "This loss takes the model input (`y_true`) and the model output (`y_pred`ict). If `y_pred` is not provided it will be created by calling the model `y_pred = model(y_true)`. Then, there are three ways of calculating the loss. They all differ in the way the mean is calculated. We have:\n",
    "\n",
    "- mean_square\n",
    "- mean_abs\n",
    "- mean_norm\n",
    "\n",
    "However, all of them are called on the output of a function called `periodic_distance()`. This function calculates the pairwise distances of all points, while recognizing periodicity. Pairwise distances of two sets of $n$ points yield a $n \\times n$ matrix. The dimensionality of the points does not matter. Distance between two points in $\\mathbb{R}^\\mathbb{N}$ space is just a scalar. Some data can lie in a periodic space (or a hypertoroidal manifold, if you're a mathematician). If the distances are greater than the provided periodicity they are wrapped around in periodic space. This means if you provide angles as y_true, they will be in the interval [$-\\pi$, $\\pi$] and the distance between $-\\frac{\\pi}{4}$ and $\\frac{\\pi}{4}$ is not $\\frac{3\\pi}{2}$, but rather $\\frac{\\pi}{2}$, because the space wraps around with periodicty $2\\pi$.\n",
    "\n",
    "**Only ever one of the different means is used as a loss. The other ones are never even calculated.**\n",
    "\n",
    "We will now use the `auto_cost()` mean_abs variant to train our NN model, but we will log all three losses to tensorboard. First of all we will use the SequentialModel provided by EncoderMap. This sequential model will create a simple Autoencoder network from the specifications in EncoderMap's Parameter class and the input. We will use the dihedral data from `asp7.csv` for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0598644",
   "metadata": {},
   "source": [
    "### Getting input data\n",
    "\n",
    "We'll use pandas to read the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0cdad8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:45.392856Z",
     "iopub.status.busy": "2023-02-07T11:14:45.392453Z",
     "iopub.status.idle": "2023-02-07T11:14:45.421892Z",
     "shell.execute_reply": "2023-02-07T11:14:45.421133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 12) (10001,)\n",
      "(10001, 13)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('asp7.csv')\n",
    "dihedrals = df.iloc[:,:-1].values.astype(np.float32)\n",
    "cluster_ids = df.iloc[:,-1].values\n",
    "print(dihedrals.shape, cluster_ids.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e057ee",
   "metadata": {},
   "source": [
    "### Setting parameters\n",
    "\n",
    "Because we will use dihedrals mapped onto the range [-pi, pi], we will use a periodicity of 2\\*pi. Also: Don't forget to turn tensorboard True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f764e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:45.426263Z",
     "iopub.status.busy": "2023-02-07T11:14:45.425720Z",
     "iopub.status.idle": "2023-02-07T11:14:45.431458Z",
     "shell.execute_reply": "2023-02-07T11:14:45.430713Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = em.Parameters(\n",
    "tensorboard=True,\n",
    "periodicity=2*np.pi,\n",
    "n_steps=100,\n",
    "main_path=em.misc.run_path('runs/custom_scalars')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be623c",
   "metadata": {},
   "source": [
    "### Subclassing the SequentialModel\n",
    "\n",
    "We create a new class inheriting form EncoderMap's `SequentialModel` and call it `MyModel`. We don't even need an `__init__()` method. Everything will be kept the same, we will just change stuff around in the method `train_step()`.\n",
    "\n",
    "The `SequentialModel` class wants two inpts: The input-shape and the parameters which will be used to deal with periodicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e3e811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:45.434894Z",
     "iopub.status.busy": "2023-02-07T11:14:45.434499Z",
     "iopub.status.idle": "2023-02-07T11:14:45.604327Z",
     "shell.execute_reply": "2023-02-07T11:14:45.603460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyModel object at 0x7f6cf3269a90>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 11:14:45.440862: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.9.16/x64/lib\n",
      "2023-02-07 11:14:45.440892: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-07 11:14:45.440914: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fv-az267-630): /proc/driver/nvidia/version does not exist\n",
      "2023-02-07 11:14:45.441179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "class MyModel(em.models.models.SequentialModel):\n",
    "    pass\n",
    "\n",
    "my_model = MyModel(dihedrals.shape[1], parameters)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4b2a5",
   "metadata": {},
   "source": [
    "Due to class inheritance the `MyModel` class can access the provided parameters as an instance variable called `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "825b9db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:45.608683Z",
     "iopub.status.busy": "2023-02-07T11:14:45.607992Z",
     "iopub.status.idle": "2023-02-07T11:14:45.613771Z",
     "shell.execute_reply": "2023-02-07T11:14:45.612990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters class with Main path at runs/custom_scalars/run0.\n",
      "Non-standard value of n_steps: 100\n",
      "Non-standard value of tensorboard: True\n"
     ]
    }
   ],
   "source": [
    "print(my_model.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fecb6d",
   "metadata": {},
   "source": [
    "### Changing what happens in a training step\n",
    "\n",
    "Now we ill change what happens in a training step. We will simply call the parent's class `train_step()` function and add our custom code. Our custom code will be added inbetween the two lines reading:\n",
    "\n",
    "```python\n",
    "parent_class_out = super().train_step(data)\n",
    "return parent_class_out\n",
    "```\n",
    "\n",
    "The `train_step()` method takes besides the usual `self` instance, an argument called data. That is a batched input to the model. After every training step, a new batch will be randomly selected and shuffled from the input dataset to ensure the model reaches a good degree of generalization. We will use this input and call the model on that to get the model's output: `self(data)`. The input and output can now be compared similarly to the `auto_loss()` function. We still need one piece to do this. We will import the `periodic_distance()` function from encodermap and use it as is.\n",
    "\n",
    "After these values have been calculated we can write them to tensorboard using the `tf.summary.scalar()` function. We will group them all into a common namespace called `Comparison_Auto_Cost`.\n",
    "\n",
    "The last thing we need to talk about: The usage of `data[0]`. This is because Tensorflow generally assumes a classification task, where data[0] is the train data and data[1] is the train labels. Because we are doing a regression task, we will not use the second part of data. The `train_step()` method of the parent class also does something similar:\n",
    "\n",
    "\n",
    "```python\n",
    "def train_step(self, data):\n",
    "    \"\"\"Overwrites the normal train_step. What is different?\n",
    "\n",
    "    Not much. Even the provided data is expected to be a tuple of (data, classes) (x, y) in classification tasks.\n",
    "    The data is unpacked and y is discarded, because the Autoencoder Model is a regression task.\n",
    "\n",
    "    Args:\n",
    "        data (tuple): The (x, y) data of this train step.\n",
    "\n",
    "    \"\"\"\n",
    "    x, _ = data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118e1272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:45.617723Z",
     "iopub.status.busy": "2023-02-07T11:14:45.617323Z",
     "iopub.status.idle": "2023-02-07T11:14:45.720877Z",
     "shell.execute_reply": "2023-02-07T11:14:45.719976Z"
    }
   },
   "outputs": [],
   "source": [
    "from encodermap.misc.distances import periodic_distance\n",
    "\n",
    "class MyModel(em.models.models.SequentialModel):\n",
    "    def train_step(self, data):\n",
    "        parent_class_out = super().train_step(data)\n",
    "        \n",
    "        # call the model on input\n",
    "        out = self.call(data[0])\n",
    "        \n",
    "        # calculate periodic distance with instance variable self.p containing parameters\n",
    "        p_dists = periodic_distance(data[0], out, self.p.periodicity)\n",
    "        \n",
    "        # use the different norms\n",
    "        mean_square = tf.reduce_mean(tf.square(p_dists))\n",
    "        mean_abs = tf.reduce_mean(tf.abs(p_dists))\n",
    "        mean_norm = tf.reduce_mean(tf.norm(p_dists, axis=1))\n",
    "        \n",
    "        # write the values to tensorboard\n",
    "        with tf.name_scope('Comparison_Auto_Cost'):\n",
    "            tf.summary.scalar('Mean Square', mean_square)\n",
    "            tf.summary.scalar('Mean Abs', mean_abs)\n",
    "            tf.summary.scalar('Mean Norm', mean_norm)\n",
    "        \n",
    "        # return the output of the parent's class train_step() function.\n",
    "        return parent_class_out\n",
    "    \n",
    "my_model = MyModel(dihedrals.shape[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f13906",
   "metadata": {},
   "source": [
    "### Running EncoderMap with the new model\n",
    "\n",
    "How do we train the model? We provide an instance of our custom model to EncoderMap's `EncoderMap` class and let it handle the rest for us.\n",
    "\n",
    "Also make sure to execute tensorboard in the correct directory:\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir . --reload_multifile True\n",
    "```\n",
    "\n",
    "If you're on Google colab, you can use tensorboard, by activating the tensorboard extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b5677a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:45.725712Z",
     "iopub.status.busy": "2023-02-07T11:14:45.725159Z",
     "iopub.status.idle": "2023-02-07T11:14:45.729719Z",
     "shell.execute_reply": "2023-02-07T11:14:45.729036Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dcc7465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:45.732823Z",
     "iopub.status.busy": "2023-02-07T11:14:45.732429Z",
     "iopub.status.idle": "2023-02-07T11:14:45.793283Z",
     "shell.execute_reply": "2023-02-07T11:14:45.792406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files are saved to runs/custom_scalars/run0 as defined in 'main_path' in the parameters.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved a text-summary of the model and an image in runs/custom_scalars/run0, as specified in 'main_path' in the parameters.\n"
     ]
    }
   ],
   "source": [
    "e_map = em.EncoderMap(parameters, dihedrals, model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a85543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:45.797402Z",
     "iopub.status.busy": "2023-02-07T11:14:45.796872Z",
     "iopub.status.idle": "2023-02-07T11:14:57.330336Z",
     "shell.execute_reply": "2023-02-07T11:14:57.329376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [00:07<12:43,  7.71s/it, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:07<01:30,  1.03it/s, Loss after step ?=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:07<01:28,  1.03it/s, Loss after step 10=44.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [00:07<00:39,  2.26it/s, Loss after step 10=44.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [00:08<00:21,  3.91it/s, Loss after step 10=44.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [00:08<00:20,  3.91it/s, Loss after step 20=38.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [00:08<00:13,  6.05it/s, Loss after step 20=38.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 26/100 [00:08<00:08,  8.73it/s, Loss after step 20=38.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [00:08<00:08,  8.73it/s, Loss after step 30=43.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [00:08<00:05, 12.02it/s, Loss after step 30=43.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 36/100 [00:08<00:04, 15.77it/s, Loss after step 30=43.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [00:08<00:03, 15.77it/s, Loss after step 40=39.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [00:08<00:02, 19.92it/s, Loss after step 40=39.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 46/100 [00:08<00:02, 24.29it/s, Loss after step 40=39.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [00:08<00:02, 24.29it/s, Loss after step 50=37.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [00:08<00:01, 28.23it/s, Loss after step 50=37.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 56/100 [00:08<00:01, 31.91it/s, Loss after step 50=37.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [00:09<00:01, 31.91it/s, Loss after step 60=38.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [00:09<00:01, 35.19it/s, Loss after step 60=38.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 66/100 [00:09<00:00, 37.83it/s, Loss after step 60=38.5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [00:09<00:00, 37.83it/s, Loss after step 70=39.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [00:09<00:00, 39.37it/s, Loss after step 70=39.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 76/100 [00:09<00:00, 40.66it/s, Loss after step 70=39.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [00:09<00:00, 40.66it/s, Loss after step 80=35.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [00:09<00:00, 41.70it/s, Loss after step 80=35.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 86/100 [00:09<00:00, 41.59it/s, Loss after step 80=35.9]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [00:09<00:00, 41.59it/s, Loss after step 90=34.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [00:09<00:00, 42.74it/s, Loss after step 90=34.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▌| 96/100 [00:09<00:00, 43.44it/s, Loss after step 90=34.8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [00:09<00:00, 43.44it/s, Loss after step 100=35.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 100/100 [00:09<00:00, 10.08it/s, Loss after step 100=35.7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Encoder_0_input with unsupported characters which will be renamed to encoder_0_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Decoder_0_input with unsupported characters which will be renamed to decoder_0_input in the SavedModel.\n"
     ]
    }
   ],
   "source": [
    "e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c705931",
   "metadata": {},
   "source": [
    "Here's what Tensorboard should put out:\n",
    "\n",
    "<img src=\"custom_scalars_1.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aab19e",
   "metadata": {},
   "source": [
    "## Second way: Writing custom metrics.\n",
    "\n",
    "A metric that is used to judge how well your model performs. In contrast to losses metrics are not actively minimized during training. Metrics often involve more complex calculations and are not carried out for every training step.\n",
    "\n",
    "**Let us write an RMSD-mertric that computes the RMSD between the input and output of the AngleDihedralCartesianEncoderMap.**\n",
    "\n",
    "The RMSD between a set of coordinates is defined as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f42fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-07T11:14:57.334963Z",
     "iopub.status.busy": "2023-02-07T11:14:57.334679Z",
     "iopub.status.idle": "2023-02-07T11:14:57.341746Z",
     "shell.execute_reply": "2023-02-07T11:14:57.341038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function rmsd in module mdtraj._rmsd:\n",
      "\n",
      "rmsd(...)\n",
      "    rmsd(target, reference, frame=0, atom_indices=None, parallel=True, precentered=False)\n",
      "    \n",
      "    Compute RMSD of all conformations in target to a reference conformation.\n",
      "    Note, this will center the conformations in place.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    target : md.Trajectory\n",
      "        For each conformation in this trajectory, compute the RMSD to\n",
      "        a particular 'reference' conformation in another trajectory\n",
      "        object.\n",
      "    reference : md.Trajectory\n",
      "        The object containing the reference conformation to measure distances\n",
      "        to.\n",
      "    frame : int, default=0\n",
      "        The index of the conformation in `reference` to measure\n",
      "        distances to.\n",
      "    atom_indices : array_like, or None\n",
      "        The indices of the atoms to use in the RMSD calculation. If not\n",
      "        supplied, all atoms will be used.\n",
      "    ref_atom_indices : array_like, or None\n",
      "        Use these indices for the reference trajectory. If not supplied,\n",
      "        the atom indices will be the same as those for target.\n",
      "    parallel : bool\n",
      "        Use OpenMP to calculate each of the RMSDs in parallel over\n",
      "        multiple cores.\n",
      "    precentered : bool, default=False\n",
      "        Assume that the conformations are already centered at the origin, and that\n",
      "        the \"rmsd_traces\" have been computed, as is done by\n",
      "        `Trajectory.center_coordinates`. The \"rmsd_traces\" are intermediate\n",
      "        calculations needed for the RMSD calculation which can be computed\n",
      "        independently on each trajectory. Note that this has the potential to\n",
      "        be unsafe; if you use Trajectory.center_coordinates and then modify\n",
      "        the trajectory's coordinates, the center and traces will be out of\n",
      "        date and the RMSDs will be incorrect.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import mdtraj as md                                      # doctest: +SKIP\n",
      "    >>> rmsds = md.rmsd(trajectory, trajectory, 0)               # doctest: +SKIP\n",
      "    >>> print rmsds                                              # doctest: +SKIP\n",
      "    array([ 0.0,  0.03076187,  0.02549562, ...,  0.06230228,\n",
      "        0.00666826,  0.24364147])\n",
      "    \n",
      "    The calculation is slightly faster if you precenter the trajectory\n",
      "    \n",
      "    >>> trajectory.center_coordinates()\n",
      "    >>> rmsds = md.rmsd(trajectory, trajectory, 0, precentered=True)\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Trajectory.center_coordinates\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This function uses OpenMP to parallelize the calculation across\n",
      "    multiple cores. To control the number of threads launched by OpenMP,\n",
      "    you can set the environment variable ``OMP_NUM_THREADS``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rmsds : np.ndarray, shape=(target.n_frames,)\n",
      "        A 1-D numpy array of the optimal root-mean-square deviations from\n",
      "        the `frame`-th conformation in reference to each of the conformations\n",
      "        in target.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mdtraj as md\n",
    "help(md.rmsd)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "dc51df8f0343454a8432f0c813aa6ebe": {
      "model_module": "nglview-js-widgets",
      "model_module_version": "3.0.1",
      "model_name": "ColormakerRegistryModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "nglview-js-widgets",
       "_model_module_version": "3.0.1",
       "_model_name": "ColormakerRegistryModel",
       "_msg_ar": [],
       "_msg_q": [],
       "_ready": false,
       "_view_count": null,
       "_view_module": "nglview-js-widgets",
       "_view_module_version": "3.0.1",
       "_view_name": "ColormakerRegistryView",
       "layout": "IPY_MODEL_dc9fe2eaa7b24b8fac14aea8d6426e66"
      }
     },
     "dc9fe2eaa7b24b8fac14aea8d6426e66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
