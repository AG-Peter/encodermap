{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68feb89b",
   "metadata": {},
   "source": [
    "# Logging Custom Scalars\n",
    "\n",
    "Run this notebook on Google Colab:\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AG-Peter/encodermap/blob/main/tutorials/notebooks_customization/writing_custom_scalars_to_tensorboard.ipynb)\n",
    "\n",
    "Find the documentation of EncoderMap:\n",
    "\n",
    "https://ag-peter.github.io/encodermap\n",
    "\n",
    "### For Google colab only:\n",
    "\n",
    "If you're on Google colab, please uncomment these lines and install EncoderMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81f28dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.047394Z",
     "iopub.status.busy": "2023-02-01T15:59:31.047171Z",
     "iopub.status.idle": "2023-02-01T15:59:31.050441Z",
     "shell.execute_reply": "2023-02-01T15:59:31.049925Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/AG-Peter/encodermap/main/tutorials/install_encodermap_google_colab.sh\n",
    "# !sudo bash install_encodermap_google_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1e4269",
   "metadata": {},
   "source": [
    "## Primer\n",
    "\n",
    "In this tutorial we will explore 2 different ways of logging custom scalars or custom data to tensorboard using EncoderMap and its codebase. First let us start with the required imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3913fd7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.053311Z",
     "iopub.status.busy": "2023-02-01T15:59:31.052799Z",
     "iopub.status.idle": "2023-02-01T15:59:31.265884Z",
     "shell.execute_reply": "2023-02-01T15:59:31.265325Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'encodermap.autoencoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mencodermap\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mem\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/encodermap/__init__.py:94\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Imports\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     95\u001b[0m     AngleDihedralCartesianEncoderMap,\n\u001b[1;32m     96\u001b[0m     Autoencoder,\n\u001b[1;32m     97\u001b[0m     EncoderMap,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncoderMapBaseCallback\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m features\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'encodermap.autoencoder'"
     ]
    }
   ],
   "source": [
    "import encodermap as em\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99013363",
   "metadata": {},
   "source": [
    "## Subclassing a model and adding tf.summary\n",
    "\n",
    "**Idea:** Log different auto_cost_variants to tensorboard and see how they compare.\n",
    "\n",
    "EncoderMap's `auto_cost()` function compares the input and output of the autoencoder. The greater the difference the higher the returned loss. The next code fragment is taken from EncoderMap's code.\n",
    "\n",
    "```python\n",
    "def auto_cost_function(y_true, y_pred=None):\n",
    "    if y_pred is None:\n",
    "        y_pred = model(y_true)\n",
    "        \n",
    "    if p.auto_cost_scale is not None:\n",
    "        if p.auto_cost_variant == \"mean_square\":\n",
    "            auto_cost = tf.reduce_mean(\n",
    "                tf.square(periodic_distance(y_true, y_pred, p.periodicity)))\n",
    "        elif p.auto_cost_variant == \"mean_abs\":\n",
    "            auto_cost = tf.reduce_mean(\n",
    "                tf.abs(periodic_distance(y_true, y_pred, p.periodicity)))\n",
    "        elif p.auto_cost_variant == \"mean_norm\":\n",
    "            auto_cost = tf.reduce_mean(\n",
    "                tf.norm(periodic_distance(y_true, y_pred, p.periodicity), axis=1))\n",
    "        else:\n",
    "            raise ValueError(\"auto_cost_variant {} not available\".format(p.auto_cost_variant))\n",
    "        if p.auto_cost_scale != 0:\n",
    "            auto_cost *= p.auto_cost_scale\n",
    "    else:\n",
    "        auto_cost = 0\n",
    "    tf.cond(write_bool, true_fn=lambda: _summary_cost('Auto Cost', auto_cost),\n",
    "            false_fn=lambda: _do_nothing(), name=\"Cost\")\n",
    "```\n",
    "\n",
    "This loss takes the model input (`y_true`) and the model output (`y_pred`ict). If `y_pred` is not provided it will be created by calling the model `y_pred = model(y_true)`. Then, there are three ways of calculating the loss. They all differ in the way the mean is calculated. We have:\n",
    "\n",
    "- mean_square\n",
    "- mean_abs\n",
    "- mean_norm\n",
    "\n",
    "However, all of them are called on the output of a function called `periodic_distance()`. This function calculates the pairwise distances of all points, while recognizing periodicity. Pairwise distances of two sets of $n$ points yield a $n \\times n$ matrix. The dimensionality of the points does not matter. Distance between two points in $\\mathbb{R}^\\mathbb{N}$ space is just a scalar. Some data can lie in a periodic space (or a hypertoroidal manifold, if you're a mathematician). If the distances are greater than the provided periodicity they are wrapped around in periodic space. This means if you provide angles as y_true, they will be in the interval [$-\\pi$, $\\pi$] and the distance between $-\\frac{\\pi}{4}$ and $\\frac{\\pi}{4}$ is not $\\frac{3\\pi}{2}$, but rather $\\frac{\\pi}{2}$, because the space wraps around with periodicty $2\\pi$.\n",
    "\n",
    "**Only ever one of the different means is used as a loss. The other ones are never even calculated.**\n",
    "\n",
    "We will now use the `auto_cost()` mean_abs variant to train our NN model, but we will log all three losses to tensorboard. First of all we will use the SequentialModel provided by EncoderMap. This sequential model will create a simple Autoencoder network from the specifications in EncoderMap's Parameter class and the input. We will use the dihedral data from `asp7.csv` for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0598644",
   "metadata": {},
   "source": [
    "### Getting input data\n",
    "\n",
    "We'll use pandas to read the .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0cdad8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.269625Z",
     "iopub.status.busy": "2023-02-01T15:59:31.269137Z",
     "iopub.status.idle": "2023-02-01T15:59:31.287107Z",
     "shell.execute_reply": "2023-02-01T15:59:31.286541Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masp7.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m dihedrals \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      3\u001b[0m cluster_ids \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('asp7.csv')\n",
    "dihedrals = df.iloc[:,:-1].values.astype(np.float32)\n",
    "cluster_ids = df.iloc[:,-1].values\n",
    "print(dihedrals.shape, cluster_ids.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e057ee",
   "metadata": {},
   "source": [
    "### Setting parameters\n",
    "\n",
    "Because we will use dihedrals mapped onto the range [-pi, pi], we will use a periodicity of 2\\*pi. Also: Don't forget to turn tensorboard True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f764e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.290182Z",
     "iopub.status.busy": "2023-02-01T15:59:31.289861Z",
     "iopub.status.idle": "2023-02-01T15:59:31.306850Z",
     "shell.execute_reply": "2023-02-01T15:59:31.306299Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'em' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[43mem\u001b[49m\u001b[38;5;241m.\u001b[39mParameters(\n\u001b[1;32m      2\u001b[0m tensorboard\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      3\u001b[0m periodicity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi,\n\u001b[1;32m      4\u001b[0m n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      5\u001b[0m main_path\u001b[38;5;241m=\u001b[39mem\u001b[38;5;241m.\u001b[39mmisc\u001b[38;5;241m.\u001b[39mrun_path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns/custom_scalars\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'em' is not defined"
     ]
    }
   ],
   "source": [
    "parameters = em.Parameters(\n",
    "tensorboard=True,\n",
    "periodicity=2*np.pi,\n",
    "n_steps=100,\n",
    "main_path=em.misc.run_path('runs/custom_scalars')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be623c",
   "metadata": {},
   "source": [
    "### Subclassing the SequentialModel\n",
    "\n",
    "We create a new class inheriting form EncoderMap's `SequentialModel` and call it `MyModel`. We don't even need an `__init__()` method. Everything will be kept the same, we will just change stuff around in the method `train_step()`.\n",
    "\n",
    "The `SequentialModel` class wants two inpts: The input-shape and the parameters which will be used to deal with periodicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e3e811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.309803Z",
     "iopub.status.busy": "2023-02-01T15:59:31.309272Z",
     "iopub.status.idle": "2023-02-01T15:59:31.324769Z",
     "shell.execute_reply": "2023-02-01T15:59:31.324214Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'em' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyModel\u001b[39;00m(\u001b[43mem\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequentialModel):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m      4\u001b[0m my_model \u001b[38;5;241m=\u001b[39m MyModel(dihedrals\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], parameters)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'em' is not defined"
     ]
    }
   ],
   "source": [
    "class MyModel(em.models.models.SequentialModel):\n",
    "    pass\n",
    "\n",
    "my_model = MyModel(dihedrals.shape[1], parameters)\n",
    "print(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4b2a5",
   "metadata": {},
   "source": [
    "Due to class inheritance the `MyModel` class can access the provided parameters as an instance variable called `p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "825b9db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.328109Z",
     "iopub.status.busy": "2023-02-01T15:59:31.327651Z",
     "iopub.status.idle": "2023-02-01T15:59:31.343246Z",
     "shell.execute_reply": "2023-02-01T15:59:31.342692Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmy_model\u001b[49m\u001b[38;5;241m.\u001b[39mp)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(my_model.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fecb6d",
   "metadata": {},
   "source": [
    "### Changing what happens in a training step\n",
    "\n",
    "Now we ill change what happens in a training step. We will simply call the parent's class `train_step()` function and add our custom code. Our custom code will be added inbetween the two lines reading:\n",
    "\n",
    "```python\n",
    "parent_class_out = super().train_step(data)\n",
    "return parent_class_out\n",
    "```\n",
    "\n",
    "The `train_step()` method takes besides the usual `self` instance, an argument called data. That is a batched input to the model. After every training step, a new batch will be randomly selected and shuffled from the input dataset to ensure the model reaches a good degree of generalization. We will use this input and call the model on that to get the model's output: `self(data)`. The input and output can now be compared similarly to the `auto_loss()` function. We still need one piece to do this. We will import the `periodic_distance()` function from encodermap and use it as is.\n",
    "\n",
    "After these values have been calculated we can write them to tensorboard using the `tf.summary.scalar()` function. We will group them all into a common namespace called `Comparison_Auto_Cost`.\n",
    "\n",
    "The last thing we need to talk about: The usage of `data[0]`. This is because Tensorflow generally assumes a classification task, where data[0] is the train data and data[1] is the train labels. Because we are doing a regression task, we will not use the second part of data. The `train_step()` method of the parent class also does something similar:\n",
    "\n",
    "\n",
    "```python\n",
    "def train_step(self, data):\n",
    "    \"\"\"Overwrites the normal train_step. What is different?\n",
    "\n",
    "    Not much. Even the provided data is expected to be a tuple of (data, classes) (x, y) in classification tasks.\n",
    "    The data is unpacked and y is discarded, because the Autoencoder Model is a regression task.\n",
    "\n",
    "    Args:\n",
    "        data (tuple): The (x, y) data of this train step.\n",
    "\n",
    "    \"\"\"\n",
    "    x, _ = data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118e1272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.346353Z",
     "iopub.status.busy": "2023-02-01T15:59:31.345697Z",
     "iopub.status.idle": "2023-02-01T15:59:31.380253Z",
     "shell.execute_reply": "2023-02-01T15:59:31.379587Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'encodermap.autoencoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mencodermap\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistances\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m periodic_distance\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyModel\u001b[39;00m(em\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequentialModel):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/encodermap/__init__.py:94\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Imports\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoencoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     95\u001b[0m     AngleDihedralCartesianEncoderMap,\n\u001b[1;32m     96\u001b[0m     Autoencoder,\n\u001b[1;32m     97\u001b[0m     EncoderMap,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncoderMapBaseCallback\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m features\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'encodermap.autoencoder'"
     ]
    }
   ],
   "source": [
    "from encodermap.misc.distances import periodic_distance\n",
    "\n",
    "class MyModel(em.models.models.SequentialModel):\n",
    "    def train_step(self, data):\n",
    "        parent_class_out = super().train_step(data)\n",
    "        \n",
    "        # call the model on input\n",
    "        out = self.call(data[0])\n",
    "        \n",
    "        # calculate periodic distance with instance variable self.p containing parameters\n",
    "        p_dists = periodic_distance(data[0], out, self.p.periodicity)\n",
    "        \n",
    "        # use the different norms\n",
    "        mean_square = tf.reduce_mean(tf.square(p_dists))\n",
    "        mean_abs = tf.reduce_mean(tf.abs(p_dists))\n",
    "        mean_norm = tf.reduce_mean(tf.norm(p_dists, axis=1))\n",
    "        \n",
    "        # write the values to tensorboard\n",
    "        with tf.name_scope('Comparison_Auto_Cost'):\n",
    "            tf.summary.scalar('Mean Square', mean_square)\n",
    "            tf.summary.scalar('Mean Abs', mean_abs)\n",
    "            tf.summary.scalar('Mean Norm', mean_norm)\n",
    "        \n",
    "        # return the output of the parent's class train_step() function.\n",
    "        return parent_class_out\n",
    "    \n",
    "my_model = MyModel(dihedrals.shape[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f13906",
   "metadata": {},
   "source": [
    "### Running EncoderMap with the new model\n",
    "\n",
    "How do we train the model? We provide an instance of our custom model to EncoderMap's `EncoderMap` class and let it handle the rest for us.\n",
    "\n",
    "Also make sure to execute tensorboard in the correct directory:\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir . --reload_multifile True\n",
    "```\n",
    "\n",
    "If you're on Google colab, you can use tensorboard, by activating the tensorboard extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b5677a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.383137Z",
     "iopub.status.busy": "2023-02-01T15:59:31.382796Z",
     "iopub.status.idle": "2023-02-01T15:59:31.385610Z",
     "shell.execute_reply": "2023-02-01T15:59:31.385005Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dcc7465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.388221Z",
     "iopub.status.busy": "2023-02-01T15:59:31.388019Z",
     "iopub.status.idle": "2023-02-01T15:59:31.402541Z",
     "shell.execute_reply": "2023-02-01T15:59:31.401915Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'em' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m e_map \u001b[38;5;241m=\u001b[39m \u001b[43mem\u001b[49m\u001b[38;5;241m.\u001b[39mEncoderMap(parameters, dihedrals, model\u001b[38;5;241m=\u001b[39mmy_model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'em' is not defined"
     ]
    }
   ],
   "source": [
    "e_map = em.EncoderMap(parameters, dihedrals, model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9a85543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.405196Z",
     "iopub.status.busy": "2023-02-01T15:59:31.404998Z",
     "iopub.status.idle": "2023-02-01T15:59:31.419474Z",
     "shell.execute_reply": "2023-02-01T15:59:31.418913Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43me_map\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e_map' is not defined"
     ]
    }
   ],
   "source": [
    "e_map.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c705931",
   "metadata": {},
   "source": [
    "Here's what Tensorboard should put out:\n",
    "\n",
    "<img src=\"custom_scalars_1.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aab19e",
   "metadata": {},
   "source": [
    "## Second way: Writing custom metrics.\n",
    "\n",
    "A metric that is used to judge how well your model performs. In contrast to losses metrics are not actively minimized during training. Metrics often involve more complex calculations and are not carried out for every training step.\n",
    "\n",
    "**Let us write an RMSD-mertric that computes the RMSD between the input and output of the AngleDihedralCartesianEncoderMap.**\n",
    "\n",
    "The RMSD between a set of coordinates is defined as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f42fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T15:59:31.422201Z",
     "iopub.status.busy": "2023-02-01T15:59:31.421881Z",
     "iopub.status.idle": "2023-02-01T15:59:31.596080Z",
     "shell.execute_reply": "2023-02-01T15:59:31.595524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function rmsd in module mdtraj._rmsd:\n",
      "\n",
      "rmsd(...)\n",
      "    rmsd(target, reference, frame=0, atom_indices=None, parallel=True, precentered=False)\n",
      "    \n",
      "    Compute RMSD of all conformations in target to a reference conformation.\n",
      "    Note, this will center the conformations in place.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    target : md.Trajectory\n",
      "        For each conformation in this trajectory, compute the RMSD to\n",
      "        a particular 'reference' conformation in another trajectory\n",
      "        object.\n",
      "    reference : md.Trajectory\n",
      "        The object containing the reference conformation to measure distances\n",
      "        to.\n",
      "    frame : int, default=0\n",
      "        The index of the conformation in `reference` to measure\n",
      "        distances to.\n",
      "    atom_indices : array_like, or None\n",
      "        The indices of the atoms to use in the RMSD calculation. If not\n",
      "        supplied, all atoms will be used.\n",
      "    ref_atom_indices : array_like, or None\n",
      "        Use these indices for the reference trajectory. If not supplied,\n",
      "        the atom indices will be the same as those for target.\n",
      "    parallel : bool\n",
      "        Use OpenMP to calculate each of the RMSDs in parallel over\n",
      "        multiple cores.\n",
      "    precentered : bool, default=False\n",
      "        Assume that the conformations are already centered at the origin, and that\n",
      "        the \"rmsd_traces\" have been computed, as is done by\n",
      "        `Trajectory.center_coordinates`. The \"rmsd_traces\" are intermediate\n",
      "        calculations needed for the RMSD calculation which can be computed\n",
      "        independently on each trajectory. Note that this has the potential to\n",
      "        be unsafe; if you use Trajectory.center_coordinates and then modify\n",
      "        the trajectory's coordinates, the center and traces will be out of\n",
      "        date and the RMSDs will be incorrect.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import mdtraj as md                                      # doctest: +SKIP\n",
      "    >>> rmsds = md.rmsd(trajectory, trajectory, 0)               # doctest: +SKIP\n",
      "    >>> print rmsds                                              # doctest: +SKIP\n",
      "    array([ 0.0,  0.03076187,  0.02549562, ...,  0.06230228,\n",
      "        0.00666826,  0.24364147])\n",
      "    \n",
      "    The calculation is slightly faster if you precenter the trajectory\n",
      "    \n",
      "    >>> trajectory.center_coordinates()\n",
      "    >>> rmsds = md.rmsd(trajectory, trajectory, 0, precentered=True)\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Trajectory.center_coordinates\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This function uses OpenMP to parallelize the calculation across\n",
      "    multiple cores. To control the number of threads launched by OpenMP,\n",
      "    you can set the environment variable ``OMP_NUM_THREADS``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    rmsds : np.ndarray, shape=(target.n_frames,)\n",
      "        A 1-D numpy array of the optimal root-mean-square deviations from\n",
      "        the `frame`-th conformation in reference to each of the conformations\n",
      "        in target.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mdtraj as md\n",
    "help(md.rmsd)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
